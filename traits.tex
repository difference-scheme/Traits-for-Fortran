\documentclass[11pt,oneside]{report}
\usepackage[a4paper, total={6.5in, 9in}]{geometry}
\usepackage{natbib}
\usepackage{url}
\usepackage{listings}
\usepackage{listings-rust}
\usepackage[scaled=0.82]{beramono}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage[title]{appendix}
\usepackage{csquotes}
\usepackage{mathpazo}
%\usepackage{mathptmx}

\newcommand{\code}[1]{{\selectfont\ttfamily{#1}}}

\lstdefinelanguage{LFortran}[]{Fortran}{
  morekeywords={abstract,type,implements,implement,initial,extension}
}

\hypersetup{
    colorlinks,
    linkcolor={green!40!black},
    citecolor={blue!70!black},
    urlcolor={blue!90!black}
}

\frenchspacing

\begin{document}

\title{A trait system for the uniform expression of run-time
       and compile-time polymorphism in Fortran}

\author{Konstantinos Kifonidis, Ondrej Certik, Derick Carnazzola}

\maketitle

\abstract{TBD.}

\chapter{Introduction}

Polymorphism was discovered in the 1960s by Kristen Nygaard and
Ole-Johan Dahl during their development of Simula~67, the world's
first object-oriented (OO) language \cite{Dahl_04}. Their work
introduced into programming what is nowadays known as ``virtual method
table'' (i.e. function-pointer) based run-time polymorphism, which is
both the first focus of this document, and the defining feature of all
OO languages. Several other forms of polymorphism are known today, the
most important of them being parametric polymorphism
\cite{Cardelli_Wegner_85} (also known as ``generics''), which is the
second focus of this document, and which has historically developed
disjointly from run-time polymorphism, since it makes use of
compile-time mechanisms.


\section{The purpose of polymorphism}

But what is the purpose of polymorphism in a programming language?
What is polymorphism actually good for? One of the more comprehensive
answers to this question was given by Robert C. Martin in numerous
books (e.g. \cite{Martin_17}), as well as in the following quotation
from his blog:

\begin{displayquote}
``There really is only one benefit to polymorphism; but it's a big
  one. It is the inversion of source code and run time
  dependencies. In most software systems when one function calls
  another, the runtime dependency and the source code dependency point
  in the same direction. The calling module depends on the called
  module. However, when polymorphism is injected between the two there
  is an inversion of the source code dependency. The calling module
  still depends on the called module at run time. However, the source
  code of the calling module does not depend upon the source code of
  the called module. Rather both modules depend upon a polymorphic
  interface. This inversion allows the called module to act like a
  plugin. Indeed, this is how all plugins work.''
\end{displayquote}

Notice, the absence of the words ``code reuse'' in these statements.
The purpose of polymorphism, according to Martin, is the ``inversion''
(i.e. replacement, or management) of source code dependencies by
(means of) particular abstractions, i.e. polymorphic interfaces (or
protocols/traits, as they are also known today). The possibility to
reuse code is then merely the logical consequence of such proper
dependency management.

\section{Source code dependencies in statically typed languages}

Which then are the source code dependencies that polymorphism helps us
manage? It has been customary to make the following distinction when
answering this question:
\begin{itemize}
\item
  Firstly, most larger programs that are written in statically typed
  languages (like Fortran) have dependencies on \emph{user-defined}
  procedures and data types. If the programmer employs encapsulation
  of both a program's procedures and its data, i.e. its state, both
  these dependencies can actually be viewed as dependencies on
  user-defined abstract data types, i.e. types that contain both
  user-defined state, and implementation code which operates on that
  (hidden) state. These are the dependencies that Martin is concretely
  referring to in the above quotation, and it is these dependencies on
  (volatile) implementation (details) that are particularly
  troublesome, because they lead to rigid coupling between the various
  different \emph{parts} of an application. Their results are
  recompilation cascades, the non-reusability of higher-level modules,
  the impossibility to comprehend a large application incrementally,
  and fragility of such an application as a whole.
\item
  Secondly, every program, that is written in a statically typed
  language, also has dependencies on abstract data types that are
  provided by the language itself. Fortran's \code{integer},
  \code{real}, etc. intrinsic types are examples of language intrinsic
  abstract data types. While hard-wired dependencies on such intrinsic
  types may not couple different parts of a program (because the
  implementations of these types are supplied by the language), they
  nevertheless make a program's source code rigid with respect to the
  data that it can be used on.
\end{itemize}

The most widely used approaches to manage dependencies on language
intrinsic types have so far been through generics, while dependency
management of user-defined (abstract data) types has so far been the
task of OO programming and OO design patterns. Martin \cite{Martin_17}
has, for instance, defined object-orientation as follows:

\begin{displayquote}
  ``OO is the ability, through the use of polymorphism, to gain
  absolute control over every source code dependency in [a software]
  system. It allows the architect to create a plugin architecture, in
  which modules that contain high-level policies are independent of
  modules that contain low-level details. The low-level details are
  relegated to plugin modules that can be deployed and developed
  independently from the modules that contain high-level policies.''
\end{displayquote}

\section{Modern developments}

Notice how Martin's modern definition of object-orientation, that
emphasizes source code decoupling, is the antithesis to the usually
taught ``OO'' approaches of one class rigidly inheriting
implementation code from another. Notice also how his definition does
not require some specific type of polymorphism for the task of
dependency management, as long as (according to Martin's first
quotation) the mechanism is based on polymorphic interfaces.

Martin's statements on the purpose of both polymorphism and OO simply
reflect the two crucial developments that have taken place in these
fields over the last decades. Namely, the realizations that
\begin{itemize}
\item
  run-time polymorphism should be freed from the conflicting concept
  of implementation inheritance (to which it was originally bound
  given its Simula~67 heritage), and be formulated exclusively in
  terms of conformance to polymorphic interfaces, i.e. function
  signatures, or purely procedural abstractions, and that
\item
  compile-time polymorphism should be formulated in exactly the same
  way as well.
\end{itemize}

These two developments taken together have recently opened up the
possibility to treat polymorphism, and hence the dependency management
of both user-defined and language intrinsic types, uniformly in a
programming language. As a consequence, it has become possible to use
the potentially more efficient (but also less flexible) mechanism of
compile-time polymorphism also for a number of tasks that have
traditionally been reserved for run-time polymorphism (i.e. OO
programming), and to mix and match the two polymorphism types inside a
single application to better satisfy a user's needs for both
flexibility and efficiency.

\section{Historical background}

The road towards these realizations has been surprisingly long. Over
the last five decades, a huge body of OO programming experience first
had to demonstrate that the use of (both single and multiple)
implementation inheritance breaks encapsulation in OO languages, and
therefore results in extremely tightly coupled, rigid, fragile, and
non-reusable code. This led to an entire specialized literature on OO
design patterns, that aimed at avoiding or mitigating the effects of
such rigidity, by replacing the use of implementation inheritance with
the means to formulate run-time polymorphism that are discussed
below. It also led to the apprehension that implementation inheritance
(but \emph{not} run-time polymorphism) should be abandoned. In modern
languages, implementation inheritance is either kept solely for
backwards compatibility reasons (e.g. in the Swift language), or it is
foregone altogether (e.g. in Rust, Go, and Carbon).

The first statically typed mainstream programming language that
offered a proper separation of run-time polymorphism from
implementation inheritance was Objective~C. It introduced
``protocols'' (i.e. polymorphic interfaces) in the year
1990. Protocols in Objective C consist of pure function signatures,
that lack implementation code. Objective~C provided a mechanism to
implement (multiple) such protocols by a class, and to thus make
classes conform to protocols. This can be viewed as a restricted form
of (multiple) inheritance, namely inheritance of object
\emph{specification}, which is also known as \emph{subtyping}. Only a
few years later, in 1995, the Java language hugely popularized these
ideas under the monikers ``interfaces'' and ``interface
inheritance''. Today, nearly all modern languages support polymorphic
interfaces/protocols, and the basic mechanism of multiple interface
inheritance that was introduced to express run-time polymorphism in
Objective~C, often in even improved, more flexible,
manifestations. The only negative exceptions in this respect being
modern Fortran, and C++, which both still stick to the obsolescent
Simula~67 paradigm.

A similar learning process, as that outlined for run-time
polymorphism, took place in the field of compile-time/parametric
polymorphism. Early attempts, notably templates in C++, to render
function arguments and class parameters polymorphic, did not impose
any constraints on such arguments and parameters, that could be
checked by C++ compilers. With the known results on compilation times
and cryptic compiler error messages. Surprisingly, Java, the language
that truly popularized polymorphic interfaces in OO programming, did
not provide an interface based mechanism to constrain its
generics. Within the pool of mainstream programming languages, this
latter realization was first made with the advent of Rust
\cite{Matsakis_2014}.

Rust came with a trait (i.e. polymorphic interface) system with which
it is possible for the user to uniformly and transparently express
both generics (i.e. compile-time) and run-time polymorphism in the
same application, and to relatively easily switch between the two,
where possible. Rust's traits are an improved form of
protocols/interfaces in that the user can implement them for a type
without having these implementations be coupled to the type's actual
definition. Thus, existing types can be made to retroactively
implement new traits, and hence be used in new settings (with some
minor restrictions on user ownership of either the traits or the
types).

Rust's main idea was quickly absorbed by almost all other mainstream
modern languages, most notably Go, Swift, and Carbon, with the
difference that these latter languages tend to leave the choice
between static and dynamic procedure dispatch to the compiler, or
language implementation, rather than the programmer. C++ is in the
process of adopting generics constraints for its ``templates'' under
the term ``strong concepts'', but without implementing the greater
idea to uniformly express \emph{all} the polymorphism in the language
through them. An implementation of this latter idea must today be
viewed as a prerequisite in order to call a language design
``modern''. The purpose of this document is to describe additions to
Fortran, that aim to provide the Fortran language with such modern
capabilities.

\chapter{Case Study: Calculating the average value of a numeric array}

To illustrate the advanced features and capabilities of some of the
available modern programming languages with respect to polymorphism,
and hence dependency management, we will make use here of a case
study: the simple test case of calculating the average value of a set
of numbers stored inside a one-dimensional array. In the remainder of
this chapter we will first provide an account and some straightforward
monomorphic (i.e. coupled) functional implementation of this test
problem, followed by a functional implementation that makes use of
both run-time and compile-time polymorphism to manage source code
dependencies. In the survey of programming languages presented in
Chapter~\ref{sect:survey}, we will then recode this test problem in an
encapsulated fashion, to highlight how the source code dependencies in
this problem can be managed in different languages even in more
complex situations, that require OO techniques.

\section{Monomorphic functional implementation}
\label{sect:mono_functional}

We have chosen Go here as a language to illustrate the basic ideas.
Go is easily understood, even by beginners, and is therefore well
suited for this purpose (another good choice would have been the Swift
language). The code in the following Listing~\ref{lst:funcGo} should
be self explanatory for anyone who is even only remotely familiar with
the syntax of C family languages. So, we'll make only a few remarks
regarding syntax.
\begin{itemize}
\item
  While mostly following a C like syntax, variable declarations in Go
  are essentially imitating Pascal syntax, where a variable's name
  precedes the declaration of the type.
\item
  Go has two assignment operators. The usual \code{=} operator, as it
  is known from other languages, and the separate operator \code{:=}
  that is used for combined declaration and initialization of a
  variable.
\item
  Go has array slices that most closely resemble those of Python's
  Numpy (which exclude the upper bound of an array slice).
\end{itemize}

Our basic algorithm for calculating the average value of an array of
integer elements employs two different implementations for
averaging. The first makes use of a ``simple'' summation of all the
array's elements, in ascending order of their array index. While the
second sums in a ``pairwise'' manner, dividing the array in half to
carry out the summations recursively, and switching to the ``simple''
method once subdivision is no longer possible.

As a result, this code has three levels of hard-wired (i.e. rigid)
dependencies. Namely,
\begin{enumerate}
\item
  function \code{pairwise\_sum} depending on function
  \code{simple\_sum}'s implementation,
\item
  functions \code{simple\_average} and \code{pairwise\_average}
  depending on functions' \code{simple\_sum}, and \code{pairwise\_sum}
  implementation, respectively, and
\item
  the entire program depending rigidly on the \code{int} data type in
  order to declare both the arrays that it is operating on, and
  the results of its summation and averaging operations.
\end{enumerate}
The first two items are dependencies on user-defined implementations,
while the third is a typical case of rigid dependency on a language
intrinsic type, which renders the present code incapable of being
applied to arrays of any other data type than \code{int}s. Given that
we are dealing with three levels of dependencies, three levels of
polymorphism will accordingly be required to remove all these
dependencies.

\lstinputlisting[language=Go,style=boxed,label={lst:funcGo},caption={Monomorphic functional version of the array averaging example in Go.}]{Code/Go/coupled.go}

\section{Polymorphic functional implementation}
\label{sect:poly_functional}

Listing~\ref{lst:polyfuncGo} gives an implementation of our test
problem, that employs Go's generics and functional features in order to
eliminate the last two of the rigid dependencies that were listed in
Sect.~\ref{sect:mono_functional} (we thank Robert Griesemer of the Go
team for providing the original code of this particular version of the
example). The code makes use of Go's generics to admit arrays of both the
\code{int} and \code{float64} types as arguments to all functions, and
to express the return values of the latter. It also makes use of the
run-time polymorphism inherent in Go's functional features, namely
closures and variables of higher-order functions, to replace the two
previous versions of function \code{average} (that depended on
specific implementations), by a single polymorphic version. Only the
rigid dependency of function \code{pairwise\_sum} on function
\code{simple\_sum} has not been removed, in order to keep the code
more readable. In the OO code versions, that will be presented in
Chapter~\ref{sect:survey}, even this dependency is eliminated.

A few remarks are in order for a better understanding of
Listing~\ref{lst:polyfuncGo}'s code:
\begin{itemize}
\item
  In Go, generic type parameters to a function, like the parameter
  \code{T} here, are provided in a separate parameter list, that is
  enclosed in brackets [ ].
\item
  Generic type parameters have a constraint that follows their
  declared name. Go exclusively uses interfaces as such constraints
  (see the interface \code{INumeric} in the present example).
\item
  Interfaces consist of either function signatures, or \emph{type
  sets}, like ``\code{int | float64}'' in the present example. The
  latter signify a set of function signatures, too, namely the
  signatures of the intersecting set of all the operations/functions
  for which the listed types provide implementations.
\item
  The code makes use of type conversions to the generic type \code{T},
  where required. For instance, \code{T(0)} converts the
  \code{integer} constant \code{0} to the corresponding zero constant
  of type \code{T}.
\item
  The code instantiates closures and stores these by value in two
  variables named \code{avi} and \code{avf} for later use (Fortran
  and C programmers should note that \code{avi} and \code{avf} are
  \emph{not} function pointers!).
\end{itemize}


\lstinputlisting[language=Go,style=boxed,label={lst:polyfuncGo},caption={Polymorphic functional version of the array averaging example in Go.}]{Code/Go/functional.go}

The motivation to code the example as in Listing~\ref{lst:polyfuncGo}
is that once the two closures \code{avi}, and \code{avf}, are properly
instantiated (by means of the \code{switch} statement), they may be
passed from the main program to any other client code that may need to
make use of the particular averaging algorithm that was selected by
the user. This latter client code would \emph{not} have to be littered
with \code{switch} statements itself, and it would \emph{not} have to
depend on any specific implementations. It would merely depend on the
closures' interfaces. The same holds for the OO code versions that are
discussed in the next chapter, with objects replacing the closures
(both being merely slightly different realizations of the same idea).

\chapter{Survey of modern languages}
\label{sect:survey}

In the present chapter we give implementations, in various modern
languages, of encapsulated (i.e. OO) code versions of the test
problem. As in the functional code version presented in
Sect.~\ref{sect:poly_functional}, we employ run-time polymorphism to
manage the dependencies on user-defined implementations (in this case
abstract data types), and generics in order to manage the dependencies
on language intrinsic types. This serves to illustrate how both
run-time and compile-time polymorphism can be typically used for
dependency management in an OO setting in these modern languages. The
survey also aims to highlight the many commonalities but also some
of the minor differences in the approaches to polymorphism that were
taken in these different languages. As a final disclaimer, we do not
advocate to code problems in an OO manner that can be easily coded in
these languages in a functional way (as it is the case for this
problem). However, in more complex cases, where many more nested
functions would need to be used, and where state would have to be
hidden, the OO programming style would be the more appropriate
one. Hence our test problem will stand in, in this chapter, for
emulating also such a more complex problem, that would benefit from an
encapsulated coding style.


\section{Go}

Go has supported run-time polymorphism through (polymorphic)
``interfaces'' (and hence modern-day OO programming) since its
inception. In Go, encapsulation is done by storing state in a
``\code{struct}'' and by binding procedures, that need to use that
state, to this same \code{struct}. Thus creating a user-defined
abstract data type (or ADT) with methods. Go allows the programmer to
implement multiple polymorphic interfaces for such a type (i.e. to use
multiple interface inheritance), even though it offers no explicit
language statement for this purpose.

Instead, a user-defined type is implicitly assumed to implement an
interface whenever it provides implementations of all the interface's
function signatures. This way of implementing interfaces requires only
an object reference of the type to be passed to its methods (by means
of a separate parameter list, in front of a method's actual name). It
is otherwise decoupled from the type's definition (i.e. the ADT's
\code{struct} definition). Limitations in Go are that language
intrinsic types cannot have methods, and that methods and interfaces
cannot be directly implemented for user-defined types whose
definitions are located in other packages. That is, the programmer has
to write wrappers in the latter case. Go, finally, makes it explicit
in its type definition syntax that interfaces (like \code{struct}'s)
are types in their own right, and that hence polymorphic variables
(i.e. objects) can be declared in terms of them.

Since version 1.18, Go also supports compile-time polymorphism through
generics. Go's generics make use of ``strong concepts'', since they
are bounded by constraints that are expressed through
interfaces. Hence, the Go compiler will fully type-check generic code.
In Go, structures, interfaces, and functions, but not methods, can all
be given their own generic type parameters.

%To allow methods to make use of such parameters one has to
%parameterize the structures and interfaces to which these methods or,
%respectively, their signatures belong.

\subsection{Encapsulated version coded in Go}

Listing~\ref{lst:OOGo} gives an encapsulated version of the test
problem coded in Go. The two different implementations of the
\code{sum} function have been encapsulated in two different ADTs named
\code{SimpleSum} and \code{PairwiseSum}, whereas a third ADT named
\code{Averager} encapsulates the functionality that is required to
perform the actual averaging. The latter two ADTs contain the
lower-level objects ``\code{other}'' and ``\code{drv}'' of
\code{ISum[T]} type as components, to which they delegate calls to
these objects' \code{sum} methods. Notice how the use of the
polymorphic interface \code{ISum[T]} in the declarations of
``\code{other}'' and ``\code{drv}'' enables either \code{SimpleSum} or
\code{PairwiseSum} objects to be plugged into their higher-level
clients.

A second interface, named \code{IAverager}, is used to enable
polymorphism for different averaging algorithms. Finally, there's a
third interface, \code{INumeric}, that serves exactly the same purpose
as in the functional polymorphic version given in
Sect.~\ref{sect:poly_functional}, namely to make all function
arguments and return values polymorphic, by admitting as input and
output parameters both the \code{int} and \code{float64} intrinsic
types.

Hence, three polymorphic interfaces were required in this code, in
order to eliminate the three levels of rigid dependencies that were
listed in Sect.~\ref{sect:mono_functional}. Notice also that,
exempting \code{INumeric}, all the interfaces and all the user-defined
ADTs need to take in generic type parameters in this example. This is
required in order to enable all the \code{sum} and \code{average}
methods to use generic type parameters in Go.

\lstinputlisting[language=Go,style=boxed,label={lst:OOGo},caption={Encapsulated Go version of the array averaging example.}]{Code/Go/mixed.go}

The main program makes use of Go's built-in structure constructors,
and constructor chaining, in order to instantiate objects of the
required ADTs. In particular, it instantiates run-time polymorphic
``\code{Averager}'' objects (depending on whether simple or pairwise
sum averaging is to take place), and it does so for both the
\code{int} and \code{float64} types separately, in order to then use
these objects on \code{int} and \code{float64} data, respectively. The
fact that \code{two} such objects are required (one for each language
intrinsic data type) is connected to the fact that in order to obtain
generic methods in Go, one has to parameterize interfaces by generic
parameters, and instantiate them with different actual data types, as
in \code{func main}'s first two code lines. A single
(i.e. unparameterized) \code{IAverager} interface therefore doesn't
suffice, which is unfortunate from the user's perspective, as some
code duplication in client code cannot be avoided in this way.

\section{Rust}

Like Go, Rust supports both run-time and compile-time polymorphism
through polymorphic interfaces, which Rust calls ``traits''. In
contrast to Go, Rust has its programmers implement traits in an
explicit manner, by using explicit ``\code{impl}'' code blocks to
provide a trait's method implementations. These same \code{impl}
blocks also serve to bind methods to a type that aren't a part of some
trait, like e.g. user-defined constructors for \code{struct}s (see the
functions named ``\code{new}'' in the following code
Listing~\ref{lst:OORust}).

In contrast to Go, Rust allows the programmer to implement traits for
both user-defined \emph{and} language intrinsic types, and to do so
for types that are located in external libraries (called ``crates'' in
Rust), as long as the traits themselves are defined in the
programmer's own crate. The reverse, namely implementing an external
trait for a user-owned type, is also possible. Only the (edge) case of
implementing an external trait for an external type is not allowed
(this is called the ``orphan rule''). The latter case requires the use
of wrappers.

Comparable to Go, Rust's generics model allows for the generic
parameterization of functions, traits, and user-defined types like
\code{struct}s. Rust does not explicitly forbid generic
methods. However, if one defines such a method within a trait, then
this will make the trait unuseable for the declaration of any ``trait
objects'', i.e. for the employment of run-time polymorphism. Thus, the
Rust programmer will in general (need to) parameterize traits and
\code{struct}s rather than any methods themselves. Rust generics are
fully type-checked at compilation time, i.e. Rust supports ``strong
concepts''.

\subsection{Encapsulated version coded in Rust}

The encapsulated Rust version of our test problem that is given in the
following Listing~\ref{lst:OORust} is in its outline quite similar to
the corresponding Go version. There are, however, a few minor
differences, that are listed in the following notes.

\begin{itemize}
\item
  Rust uses angled brackets to indicate generic parameter lists.
\item
  Generics constraints in Rust are typically enforced by specifying
  the required traits in \code{impl} blocks using \code{where}
  statements.
\item
  Use of a ``\code{Num}'' trait from the external ``\code{num}'' crate was
  necessary, in order to enable numeric operations on generic types,
  which leads to dependency on external library code.
\item
  At times, use of the ``\code{Copy}'' trait also had to be made, to
  work around Rust's default move semantics.
\item
  In order to help make all of the source code dependencies explicit,
  our Rust version employs modules, and \code{use} statements to import
  the required functionality.
\item
  Despite reliance on external dependencies, conversion to generic
  types wasn't possible. This led to the necessity to move the type
  conversion from method \code{average} to its calls in the main
  program. We also had to import a \code{zero} generic function from
  the external ``\code{num}'' crate, in order to initialize the
  variable \code{s} that is returned by the \code{sum} method of the
  \code{SimpleSum} ADT.
\item
  Rust's default structure constructors suffer from the same flaw as
  Fortran's. That is, they are unable to initialize from an external
  scope, structure components that are declared being private to their
  module. As in Fortran, use of user-defined constructors must be made
  instead (see the functions named ``\code{new}'' that are defined in
  separate \code{impl} blocks for the ADTs \code{PairwiseSum} and
  \code{Averager}).
\item
  To declare run-time polymorphic variables one has to put so-called
  ``trait objects'' into ``Boxes'', i.e. to declare smart pointers of
  them, for dynamic instantiation and memory allocation (this is the
  Rust equivalent to using \code{allocatable} polymorphic objects in
  Fortran).
\end{itemize}

\lstinputlisting[language=Rust,style=boxed,label={lst:OORust},caption={Encapsulated Rust version of the array averaging example.}]{Code/Rust/mixed_poly/src/main.rs}

The main program in the Rust version is somewhat longer then in the
corresponding Go version because of the need to import dependencies
from modules (as it would be necessary in realistic situations). Its
logic is also somewhat convoluted compared to the Go version, because
Rust doesn't allow the programmer to declare variables that aren't
initialized upon declaration, and because of the aforementioned
necessity to move the required type conversions out of method
\code{average}, and into the calls of this method. Otherwise the codes
are pretty much identical.


\section{Swift}

Being a successor language to Objective~C, Swift differs slightly from
the languages considered so far in that it opted to retain
implementation inheritance for backwards compatibility to Objective~C,
whereas both Go and Rust do not support implementation inheritance
\emph{by design}. Swift therefore supports ``classical'' classes, but
it also allows one to bind methods to structures (which, in contrast
to classes, are value types in Swift).

Like Go and Rust, Swift (furthermore) supports a trait system in order
to implement both run-time and compile-time polymorphism through
polymorphic interfaces, that are called ``protocols'' in Swift. If the
Swift programmer chooses to ignore implementation inheritance and
classes, he can therefore very much program with structures and
protocols in Swift as he would with structures and interfaces/traits
in Go and Rust, respectively.

Given Swift's backwards compatible design, implementation of a
protocol (i.e. interface inheritance) is usually done as in
``classical'' OO languages, i.e. within a structure's or a class's
definition. The ``\code{:}'' operator followed by one or more
interface names must be supplied for this purpose after the
structure's or class's own name. However, a very powerful facility for
types to implement protocols retroactively is also provided, through
so-called ``\code{extension}s'', that work even if the types' source
code is inaccessible (because one is, e.g., working with a library in
binary form). This same facility also allows the implementation of
protocols for language-intrinsic types. For instance, the following
little program prints out ``\code{I am 4.9}'':
\lstinputlisting[language=Swift,style=boxed]{Code/Swift/extension.swift}

Swift generics support ``strong concepts'', and are thus fully
type-checked at compile time, and their capabilities are on par with
those of Go and Rust. In one aspect they are even superior, namely in
that Swift allows for parameterized \emph{methods}, instead of
parameterized protocols. This has some interesting, postive
consequences for the Swift programmer, that will be discussed in
detail below.

\subsection{Encapsulated version coded in Swift}

Listing~\ref{lst:OOSwift} gives an example of how the encapsulated
version of the array averaging test problem can be programmed in
Swift. See the following remarks in order to understand this code:

\begin{itemize}
  \item
    Swift uses angled brackets \code{<>} to indicate generic parameter
    lists.
  \item
    Type constraints are formulated by supplying a protocol name after a
    type parameter (separated by a colon).
  \item
    Swift does not supply an equivalent to Go's \code{int | float64}
    syntax. Hence the user must use a \code{Numeric} protocol defined
    by the standard library, as a constraint for numeric types. Which
    leads to reliance on library code.
  \item
    Unfortunately, Swift's \code{Numeric} protocol does \emph{not} support
    the division operation! Hence the division that would have been required
    in function \code{average} of the \code{Averager} struct had to be moved
    out to the calling code of the main program.
  \item
    The Swift version makes use of language built-in, default, structure
    constructors (called ``initializers'').
  \item
    Array slices are not arrays themselves. So an explicit conversion
    using an \code{Array()} constructor is required in such cases.
  \item
    By default, function and method calls in Swift make use of keyword
    arguments.
  \item
    The syntax for type conversion into a generic type \code{T} is
    somewhat peculiar. E.g. Go's \code{T(0)} is written as
    \code{T(exactly:0)!} in Swift (making use of the mandatory keyword
    ``\code{exactly}'' in the function responsible for the type
    conversion).
\end{itemize}

\lstinputlisting[language=Swift,style=boxed,label={lst:OOSwift},caption={Encapsulated Swift version of the array averaging example.}]{Code/Swift/mixed.swift}

Even a casual glance at the Swift version will show that the Swift
code is the easiest to read and understand among all the encapsulated
implementations. This is largely the result of Swift supporting
generic methods, and hence not requiring the programmer to
parameterize and instantiate any generic interfaces/protocols, in
contrast to both Go and Rust. The consequences are
\begin{itemize}
\item
that method genericity for an ADT's objects can be expressed using
only a single, as opposed to multiple protocols,
\item
that merely a \emph{single} object instance of that same protocol is
required, in order to be able to operate on many different language
intrinsic data types, and
\item
that this also largely \emph{obviates the need for manual instantiations
of generics in Swift} (because generic functions/methods are easier to
instantiate automatically by the compiler, as it can always infer the
required types by checking the actual arguments that are passed to a
function/method)!
\end{itemize}

As an example, consider the \code{IAverager} protocol in the above
Swift code. There's only a single (i.e. unparameterized) version of
this protocol. Consequently, there's only a need in the main program
to declare a single object variable, \code{av}, of that protocol (that
enables \code{av} to be polymorphically assigned different
\code{struct}s that implement \code{IAverager}). Because it contains
an ``\code{average}'' method that is generic, this \emph{single}
object can then be straightforwardly used on data of \emph{both} the
\code{Int} and \code{Float64} types!

This vastly simplifies client code that needs to make use of objects
such as \code{av}, especially if such client code needs to work on
\emph{many} more types than just \code{Int} and
\code{Float64}. Contrast this with Go's and Rust's model, where manual
instantiation of a different version of \code{IAverager} is required
for \emph{every} different generic type parameter that the user wishes
to employ. Notice also, how there's \emph{not a single manual
instantiation} of generics code required in the Swift example! We
consider these significant advantages of the generics approach that is
taken in Swift vs. that of Go and Rust.


\section{Conclusions}

The use of run-time polymorphism by means of interfaces is rather
similar in all the languages considered here. The most significant
differences (that were not concretely explored here) appear to be that
Go has stricter limitations on retroactively implementing interfaces
for existing types than the other languages. Whereas Rust (with some
minor restrictions), and Swift allow the implementation of an interface
by some type to be accomplished independently from the type's
definition site. Rust and Swift thereby overcome Haveraaen et al.'s
critique \cite{Haveraaen_et_al_19} of Java regarding this point. In
fact, it is \emph{interface inheritance} which makes the uniform
polymorphic treatment of both intrinsic and user-defined types
possible in the first place in Rust and Swift, that Haveraaen et
al. seem to also (rightly) demand. In the following we will make some
final comments on the differences in all these languages' generics
features.

\subsection{Go}

Go's basic model to implement generics allows structures, interfaces,
and ordinary functions, but not methods, to be given their own generic
type parameters. The lack of true generic methods makes some
duplication of instantiation code in clients
unavoidable. Nevertheless, generic Go code is quite easy to read and
to understand. What sets Go apart from the other languages is its
built-in, easy to use support for conversion to generic types, and
especially its brilliant new notion to interpret interfaces as type
sets, along with its syntax to support this notion. This enables the
Go programmer to easily tailor constraints on generic types to his
specific needs, which is what makes the use of generics in Go
pleasant. We consider these latter particular features of Go as ``must
haves'' for Fortran.

\subsection{Rust}

Rust's basic model for generics is similar to Go's in that it allows
for parameterization of structures, interfaces, and ordinary
functions. Hence, what has been said above for Go in this respect
holds also for Rust. Rust has, unfortunately, some quirks which render
its use for the management of all types of dependencies through
polymorphism somewhat sub-optimal when compared to the other languages
considered here. The language is unpleasant to use, because of its
``borrow checker'', its \emph{excessive} obsession with type safety,
its employment of move semantics by default, and its overall C++-like
philosophy to copiously rely on external dependencies, even for the
most basic tasks, like initializing a generic type. The Rust version
of our test case is therefore marred by some dependencies on external
libraries, which is somewhat contrarian to the purpose of programming
in a polymorphic fashion, namely to avoid rigid dependencies. But even
with the functionality provided by such external dependencies, Rust
doesn't allow type conversion to generic types within generic
routines. A necessary capability for numerical work that is, for
instance, built into Go. The points we like most about the language
are its idea to decouple trait implementations from a \code{struct}'s
definition through explicit \code{impl} blocks, and the complete
control over the use of dynamic vs. static dispatch that Rust affords
the programmer. These are particular features of Rust that, in our
opinion, Fortran should borrow in some form.

\subsection{Swift}

Swift's basic model of implementing generics by allowing parameterized
structures and methods (but not parameterized interfaces) is both the
easiest to read, and the easiest to use from a programmer's
perspective. Swift's generics design allows the Swift compiler to
instantiate generics largely automatically, through inspection of the
argument types that are passed to functions and methods. In contrast
to the other languages, in Swift, the user basically never has to
bother with instantiating a generic function, a method, and often not
even a structure or a class.

If the Swift programmer knows how to write generic functions, his
knowledge automatically translates into coding generic methods, since
generic functions can be transformed into generic methods without
requiring any changes to their function signatures. This property is
helpful for the refactoring of non-OO codes into corresponding OO
versions.

We hence consider Swift's generics to be the most attractive model to
base Fortran's basic generic capabilities on, provided that it can be
implemented sufficiently easily. The fact that Swift is a language
that does not put emphasis on numerics, and whose present standard
library therefore does not provide a truly useful \code{Numeric}
protocol (that supports all the usual numeric operations), is of
absolutely no consequence for adopting Swift's basic generics design
for Fortran.

Fortran will necessarily do a better job in this respect, both by
borrowing Go's idea of interpreting type sets as interfaces, so that
the user can easily implement his own type constraints. But also by
making accessible to the user a set of language-built in interfaces
that are truly useful for numeric operations, and are implemented by
Fortran's intrinsic types.


\chapter{Fortran additions I: Basic enhancements}

\section{Sealed derived types}

\section{Improved handling of constructors}

\subsection{Structure constructors}

\subsection{User-defined constructors}

\section{File extension with new defaults}


\chapter{Fortran additions II: Subtyping}

\section{Named abstract interfaces (traits)}

The most important of all the new additions to Fortran, that are
described in this document, is the capability to define named abstract
interfaces, or traits (i.e. named collections of procedure
signatures), and to declare instance variables of them. Named abstract
interfaces are the crucial feature that is required in order to
uniformly and properly express both run-time and compile-time
polymorphism (i.e. generics) in the language, and to thereby enable a
uniform management of dependendencies on both user-defined \emph{and}
language-intrinsic types.

\subsection{Interface definitions}

Fortran already allows the programmer to define unnamed abstract
interfaces, but in order to use these as types, named versions of them
are required, as in the following example, that defines two such named
interfaces, \code{IAddition} and \code{ISubtraction}:
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: IAddition
      function add(a,b) result(c)
         real, intent(in) :: a, b
         real             :: c
      end function add
   end interface

   abstract interface :: ISubtraction
      function sub(a,b) result(c)
         real, intent(in) :: a, b
         real             :: c
      end function sub
   end interface
\end{lstlisting}
Since this is a simple addition to Fortran, that merely aims to
further extend the use cases of abstract interfaces in the language
(which presently serve as bounds on the signatures of procedure
pointers, and methods of abstract classes), it is fully backwards
compatible.

\subsection{Variable declarations}

Named abstract interfaces/traits are types in their own right. Their
purpose is to allow the programmer to declare variables in terms of
them. Either directly, i.e. as objects of such interfaces in run-time
polymorphism, or as constraints on generic type parameters in
compile-time polymorphism (see Sect.~\ref{} for examples of the
latter).

In particular, in order to use abstract interfaces for the support of
run-time polymorphic objects with dynamic method dispatch, Fortran's
\code{type} specifier for variable declarations needs to be enhanced
to accept named abstract interfaces, like in the following two
examples:
\begin{lstlisting}[language=LFortran,style=boxed]
  type(IAddition), allocatable :: adder
  type(IAddition), pointer     :: adderptr
\end{lstlisting}
The semantics here are that whenever a named abstract interface
appears \emph{directly} within the \code{type} specifier of an
object's declaration, then all the \code{public} methods of that
object, whose signatures are prescribed by the adopted interface, will
make use of late binding. That is, their calls will be resolved by the
run-time system of the language (e.g. through a virtual method
table). Since this requires that such ``trait objects'' (like
\code{adder} or \code{adderptr} in this example) be instantiated at
run time, it also entails that such objects be either declared using
the \code{allocatable}, or the \code{pointer} attribute (as in the
examples above), or that they be the arguments of a procedure.


\subsection{Extends specifier for interfaces}

Abstract interface definitions must allow the programmer to declare
new interfaces that are the union of \emph{multiple} simpler ones
(multiple interface inheritance).  In the following example, the
interface \code{IBasicMath} inherits the signatures of both the
interfaces \code{IAddition}, and \code{ISubtraction}, making
\code{IBasicMath} at the same time a \emph{subtype} of both these
simpler interfaces. That is, objects that adopt/implement the
\code{IBasicMath} interface (i.e. they conform to it), can also be
used in settings that require conformance to either the
\code{IAddition}, or \code{ISubtraction} interfaces.
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface, extends(IAddition,ISubtraction) :: IBasicMath
   end interface
\end{lstlisting}

\subsection{Short-hand notation for union of interfaces}

There are often cases where the union of two (or more) interfaces is
required but where one would not like to go through the labor to
explicitly set up a separate derived interface, like \code{IBasicMath}
above. This can be useful in variable declarations. In such cases, it
should be possible to specify the following
\begin{lstlisting}[language=LFortran,style=boxed]
   type(IAddition + ISubtraction), allocatable :: addsub
\end{lstlisting}
instead of having to explicitly derive \code{IBasicMath} from
\code{IAddition} and \code{ISubtraction}, as above, and then use it as
follows:
\begin{lstlisting}[language=LFortran,style=boxed]
   type(IBasicMath), allocatable :: addsub
\end{lstlisting}


\section{Multiple interface inheritance for types}

The language must make it possible not only for named interfaces to
conform to other named interfaces, but also for \emph{other types} to
do the same, regardless of whether such types are user-defined or
intrinsic to the language.


\subsection{Implements specifier for derived type definitions}

User-defined (i.e. derived) types can be made to conform to an
interface by means of an \code{implements} specifier in derived type
definitions.  In the following example the derived type
\code{BasicMath} implements (i.e. conforms to, or adopts) the
interface \code{IBasicMath} that was defined above
\begin{lstlisting}[language=LFortran,style=boxed]
module basic
  
   type, implements(IBasicMath) :: BasicMath
   contains
      procedure, nopass :: add
      procedure, nopass :: sub
   end type BasicMath

contains

   function add(a,b) result(c)
      real, intent(in) :: a, b
      real             :: c
      c = a + b
   end function add

   function sub(a,b) result(c)
      real, intent(in) :: a, b
      real             :: c
      c = a - b
   end function sub
      
end module basic      
\end{lstlisting}
by providing implementations of all the method signatures that are
contained in that interface. Hence, \code{BasicMath} can now be used
in client code that requires conformance to either one of the
interfaces \code{IBasicMath}, \code{IAddition}, or \code{ISubtraction}.

It is crucial, for flexibility, that the above interface inheritance
mechanism allows for a type to implement \emph{multiple} different
interfaces. For instance, if we wouldn't have defined the interface
\code{IBasicMath} from above, and would nevertheless need to use
objects of type \code{BasicMath} in settings that require conformance
to either the \code{IAddition}, or \code{ISubtraction} interfaces,
then we would define type \code{BasicMath} as follows (skipping for
brevity the implementation of the actual methods, that would have to
be done as in the previous example):
\begin{lstlisting}[language=LFortran,style=boxed]
   type, implements(IAddition,ISubtraction) :: BasicMath
   contains
      procedure, nopass :: add
      procedure, nopass :: sub
   end type BasicMath
   ...
\end{lstlisting}


\subsection{Extensions for types}

In order to avoid having to wrap existing types into wrappers, when
unforeseen new use cases come up, it should be possible (as in Swift
or Rust) to make \emph{any} type implement new interfaces, regardless
of where its original type definition is located, or whether the type
is a user-defined or a language intrinsic one. This also means that
methods should be allowed for \emph{intrinsic} types. The
\code{extension}s described below are the language feature that is
aimed at accomplishing these capabilities. The feature is modelled
after \code{extension}s in Swift, in order to enable retroactive
implementation of new methods, additional constructors, and especially
new interfaces, for types.

Swift's extensions fulfill essentially the same purpose as Rust's
\code{impl} blocks in this respect. They have been adjusted here to
Fortran's syntax that binds methods to types through declaration
blocks, rather than by including the actual implementation bodies
themselves into such a block (the implementations need to be supplied
as module procedures, as is usual in Fortran). The syntax of the
feature is largely symmetric to that of derived type definitions. Most
of the options that are allowed for type-bound procedure declarations
in derived type definitions, are therefore also allowed for such
declarations within \code{extension}s.

\subsubsection{Retroactively adding methods to a type}

Suppose that we would like to add, from within a different module, two
more methods to the \code{BasicMath} type from above, in order to give
this type some additional functionality. This can be done using an
\code{extension} as follows:
\begin{lstlisting}[language=LFortran,style=boxed]
module extended

   use basic, only: BasicMath

   public :: BasicMath
   
   extension :: BasicMath
      procedure, nopass :: mul
      procedure, nopass :: div
   end extension BasicMath

contains
   ...
end module extended
\end{lstlisting}
where the actual implementations of the \code{mul} and \code{div}
procedures would be given after the module's \code{contains} statement
as usual.

\subsubsection{Retroactively implementing interfaces by a type}

Assume now that the purpose of our addition of the previous two
methods was to actually make \code{BasicMath} conform to settings
where implementations of multiplication or division of \code{real}s
are required, and where the required functionality is described by two
interfaces called \code{IMultiplication} and \code{IDivision}. So far
we have added the code of the required methods, but we haven't made
\code{BasicMath} pluggable into code that is written in terms of
either one of these latter interfaces. To fix this, we simply state
that the \code{BasicMath} type already has all of the required
functionality, by acknowledging this with an \code{implements}
specification for these two interfaces as follows:
\begin{lstlisting}[language=LFortran,style=boxed]  
   use extended, only: BasicMath
  
   extension, implements(IMultiplication,IDivision) :: BasicMath
   end extension BasicMath

\end{lstlisting}
We could have also skipped these two steps, to instead adopt the
interfaces and provide the methods simultaneously, splitting the
\code{extension} statements along the way to adopt one interface at a
time, like so:
\begin{lstlisting}[language=LFortran,style=boxed]  
   use basic, only: BasicMath
  
   extension, implements(IMultiplication) :: BasicMath
      procedure, nopass :: mul
   end extension BasicMath

   extension, implements(IDivision) :: BasicMath
      procedure, nopass :: div
   end extension BasicMath
   ...
\end{lstlisting}
The result would have been the same. Such splitting of
\code{extension} statements can be useful to improve readability, if
different interfaces contain multiple procedure signatures, that would
all have to be implemented. These two statements (together with the
required implementations), could then even be distributed among
different modules and files.

\subsubsection{Adding new initializers}

Like derived type definitions, extensions can contain declarations of
user-defined constructor functions with the \code{initial} specifier,
in order to overload Fortran's default structure constructor with
these user-defined functions.


\chapter{Fortran additions III: Generics}

The new features that were discussed in the previous chapter are
required in order to uniformly express and support both run-time and
compile-time polymorphism in Fortran. We will now proceed with
discussing some further enhancements that are exclusively required in
order to further support compile-time polymorphism, i.e. generics.

\section{Interfaces containing generic procedure signatures}
\label{sect:generic_interfaces}

Abstract interfaces should be allowed to contain signatures of generic
procedures, as in Swift. Go's and Rust's approach to parameterize
abstract interfaces themselves, appears not as attractive from a
user's perspective. The following code shows, as an example, an
abstract interface named \code{ISum} that contains the signature of a
generic type-bound procedure named \code{sum}:
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: ISum
      function sum{INumeric :: T}(self,x) result(s)
         type(ISum), intent(in) :: self
         type(T),    intent(in) :: x(:)
         type(T)                :: s
      end function sum
   end interface
\end{lstlisting}

The example illustrates the use of a generic type parameter, i.e.  a
meta-type, or a \emph{type of types}. In this example, this type
parameter is simply called \code{T}, and it is preceded by the name of
an abstract interface that expresses a constraint on the type
parameter. Fortran generics thus support ``strong concepts''. Both,
the type parameter and its constraint, are part of a generic type
parameter list that is enclosed in curly braces, and follows
immediately behind the procedure's name. Notice that, since \code{T}
is a meta-type, the syntax used above, that deviates slightly from how
Fortran's usual function arguments are declared, appears justified as
it reflects that, in type parameters, one is dealing with different
entities.

\section{Interfaces as type sets}

\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: INumeric
      integer | real(real64)
   end interface
\end{lstlisting}

Different ``length'' parameters for character variables would be
handled in the same fashion. The following interface would, for the
lack of a better example, be used to only admit \code{character}
variables with a length of either 4 or 8 characters:
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: IPrintable
      character(len=4) | character(len=8)
   end interface
\end{lstlisting}

For simple use cases, it should be optionally possible for the
programmer to employ a shorter notation for declaring type constraints
than having to write a separate interface like \code{IPrintable}, or
\code{INumeric} above. As in the following modification of interface
\code{ISum}'s declaration, that was given previously in
Sect.~\ref{sect:generic_interfaces}:
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: ISum
      function sum{integer | real(real64) :: T}(self,x) result(s)
         type(ISum), intent(in) :: self
         type(T),    intent(in) :: x(:)
         type(T)                :: s
      end function sum
   end interface
\end{lstlisting}
The above notation would then define an abstract interface implicitly,
to be used as a type constraint for type \code{T}. In this particular
case, to admit only the default \code{integer}, or \code{real(real64)}
types, for \code{T}.

\section{Predefined interfaces for expressing common constraints}

The language should ideally supply some predefined, commonly used generic
constraints in the form of abstract interfaces that are contained in a
language intrinsic module. The actual implementation of these interfaces
could then, of course, employ the ``interfaces-as-type-sets'' syntax that
was described above. For instance, a more general \code{INumeric}
interface than the one given above, could be implemented as follows:
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: INumeric
      integer(*) | real(*) | complex(*)
   end interface
\end{lstlisting}
Notice how this makes use of kind parameters to include all
\code{integer}, \code{real}, and \code{complex} types, admitted by the
language, in a single \code{abstract interface} constraint.
Such language provided, interfaces could then be used from user code
through a \code{use} statement like in the following example for
\code{INumeric}
\begin{lstlisting}[language=LFortran,style=boxed]
module user_code

   use, intrinsic :: generic_constraints, only: INumeric

   abstract interface :: ISum
      function sum{INumeric :: T}(self,x) result(s)
         type(ISum), intent(in) :: self
         type(T),    intent(in) :: x(:)
         type(T)                :: s
      end function sum
   end interface

end module user_code
\end{lstlisting}
for use as a constraint in function and derived type implementations,
or in other interfaces, like \code{ISum} here, that require the
functionality of \code{INumeric}.

\section{Conversions to generic types}

\section{Generic type parameters for methods and procedures}

As already mentioned above, LFortran's design of generics should
follow Swift's, if possible, and allow both ordinary and type-bound
procedures (i.e. methods) to be given their own generic type
parameters. An implementation of the generic method \code{sum} of
Sect.~\ref{sect:generic_interfaces}, that is bound to a derived type
with name \code{SimpleSum}, would look as follows:
\begin{lstlisting}[language=LFortran,style=boxed]
   function sum{INumeric :: T}(self,x) result(s)
      type(SimpleSum), intent(in) :: self
      type(T),         intent(in) :: x(:)
      type(T)                     :: s
      integer :: i
      s = T(0)
      do i = 1, size(x)
         s = s + x(i)
      end do
   end function sum
\end{lstlisting}
Whereas the next example illustrates how the same procedure would look
as a stand-alone (i.e. non-encapsulated) generic function:
\begin{lstlisting}[language=LFortran,style=boxed]
   function sum{INumeric :: T}(x) result(s)
      type(T), intent(in) :: x(:)
      type(T)             :: s
      integer :: i
      s = T(0)
      do i = 1, size(x)
         s = s + x(i)
      end do
   end function sum
\end{lstlisting}

\section{Generic type parameters for derived types}

In addition to procedures, generic type parameter lists must be allowed
also for derived types, as in the following example, in which 
the interface \code{ISum} from above is implemented by a parameterized
derived-type named PairwiseSum:
\begin{lstlisting}[language=LFortran,style=boxed]
   type, implements(ISum) :: PairwiseSum{ISum :: U}
      private
      type(U) :: other
   contains
      procedure :: sum
   end type PairwiseSum
\end{lstlisting}
\code{PairwiseSum} depends on a generic type parameter \code{U}, that
is used within \code{PairwiseSum} itself in order to declare a field
variable of \code{type(U)}, which is named \code{other}. As is
indicated by the type constraint on \code{U}, object \code{other}
conforms to the \code{ISum} interface itself, and therefore contains
its own implementation of the \code{sum} procedure.


\section{Generic type parameters for structure constructors}
\label{sect:param_constructors}

If a derived type is parameterized with a generic type, then its
structure constructor must also be assumed to be parameterized with
the same generic type. Hence, calls of structure constructors that are
instantiated with particular argument types replacing the generic type
parameters of their derived types, like e.g.
\begin{lstlisting}[language=LFortran,style=boxed]
   Averager{SimpleSum}()
   Averager{PairwiseSum{SimpleSum}}()
\end{lstlisting}
must be legal. Here, \code{SimpleSum} would be a derived type that
implements the \code{ISum} interface, but (in contrast to the
\code{PairwiseSum} and \code{Averager} types) is not parameterized by
any generic type parameters itself.


\section{Extensibility to rank genericity}

Fortran's special role, as a language that caters to numeric
programming, demands that any generics design for the language must
allow for the possibility to also handle genericity of array rank. The
present design offers a lot of room in this respect. But for the
purpose of a very first prototype implementation of the generics
features discussed here this is not essential, and we thus prefer to
focus on such an extension in a future document.

\chapter{Proposed Fortran versions of the test example}

\section{Functional version}

{\sf (What to do about this one, given that Fortran doesn't have Go's
  functional programming capabilities? In this case, I think it should
  be sufficient to demonstrate only the decoupling of the argument
  types through generics, and leave all the other coupling in, as
  it is the case in the coupled functional Go version.)}

\section{Encapsulated version}

Listing~\ref{lst:OOFortran} gives our Fortran version of the
encapsulated form of the test example that corresponds to the code
versions that were presented in Chapter~\ref{sect:survey} for all the
other languages.

\begin{itemize}
\item
  We employ here the Go borrowed syntax \code{integer | real(real64)}
  to implement the interface \code{INumeric}, that is used in order to
  express type genericity for the array \code{x} and the result of the
  summation \code{s} in our different implementations of method
  \code{sum}.
\item
  As in the corresponding Go version, \code{INumeric} is defined by
  the user himself as a type set consisting of the set of intersecting
  operations defined in Fortran for the \code{integer} and
  \code{real(real64)} types.  There is thus no need for an external
  dependency.
\item
  The remaining interfaces \code{ISum} and \code{IAverager} make use
  of generic methods that are declared in terms of \code{INumeric}.
  However, in contrast to the Go version, none of these interfaces is
  parameterized itself, since we followed Swift's model of generics.
\item
  Interface inheritance is expressed through the presence of the
  \code{implements(...)} specifier in a derived-type definition
  (equivalent to Swift).
\item
  Conversions to generic types are done as in Go. Notice, how the
  compiler will have to do the necessary replacements of, e.g.,
  \code{T(0)} in function \code{sum} of class \code{SimpleSum} by
  calls to Fortran's correct conversion functions for integer and real
  types of the right kinds.
\item
  The example code makes use, in the main program, of the new
  structure constructors, with their enhancements that were discussed
  in Sect.~\ref{sect:param_constructors}, for the classes
  \code{Averager}, \code{SimpleSum}, and \code{PairwiseSum}.
\item
  The Fortran version makes use of modules and \code{use} statements
  with \code{only} clauses, in order to make explicit the source code
  dependencies of the different defined classes.
\end{itemize}

\lstinputlisting[language=LFortran,style=boxed,label={lst:OOFortran},caption={Proposed encapsulated Fortran version of the array averaging example.}]{Code/Fortran/mixed.ft}

The most important point to notice in Listing~\ref{lst:OOFortran} is
how the main program is the only part of the code that (necessarily)
depends on implementations. The \emph{entire} rest of the code depends
merely on abstract interfaces (see the \code{use} statements in the
above modules). The Fortran version described here is therefore as
clean as the Go implementation with respect to dependency management,
and as easy to use as the Swift implementation.

The features described in this document have enabled us to avoid
rigidity in the program, by both decoupling it and making it operate
on multiple data types, thus allowing for a maximum of code
reuse.

\section{Encapsulated (mostly) static version}

To finally demonstrate how methods can be made to use static, as
opposed to dynamic dispatch, Listing~\ref{lst:staticFortran} gives a
version of the encapsulated Fortran code that contains all the
required changes, as compared to Listing~\ref{lst:OOFortran}, to
effect static dispatch of the \code{sum} methods.

The changes are confined to a parameterization of the
\code{PairwiseSum} and \code{Averager} derived types, by generic type
parameters that are named \code{U}. These type parameters are then
used in order to statically declare the field objects ``\code{other}''
and ``\code{drv}'' of these derived types, respectively, that were
previously declared as \code{allocatable} variables that were to be
initialized dynamically at run-time. Correspondingly, there is no
longer any such dynamic instantiation necessary for these objects. The
only things that are required are instantiations of the parameterized
derived types in which these objects are contained. Notice how these
instantiations are carried out from the main program within the calls
of \code{Averager}'s constructor, which is provided with the types
\code{SimpleSum}, and \code{PairwiseSum}.


\lstinputlisting[language=LFortran,style=boxed,label={lst:staticFortran},caption={Encapsulated Fortran version of the array averaging example with static method dispatch.}]{Code/Fortran/static.ft}

Notice also, that in Listing~\ref{lst:staticFortran}, the \code{av}
object of \code{IAverager} type that is initialized in the
\code{select case} statement of the main program still needs to make
use of run-time polymorphism. This object cannot be made to employ
compile-time polymorphism, as it is used within a statement that
performs a run-time decision.

As a final remark we'd like to emphasize that a coding style as that
given in Listing~\ref{lst:OOFortran} should generally be preferred
over that of Listing~\ref{lst:staticFortran}, as it leads to more
readable code. The use of numerous generic parameters can quickly make
code unreadable. We'd therefore recommend the default use of run-time
polymorphism for managing dependencies on user implementation code,
and the employment of generics with static dispatch for this latter
task only in cases where profiling has shown that static dispatch
would significantly speed up a program's execution (by allowing method
inlining by the compiler). Of course, the use of generics to manage
dependencies on language intrinsic types remains unaffected by this
recommendation.

\chapter{Comparison to J3's generics proposal for Fortran~202y}

{\sf Feel free to add a corresponding code version here,
since I am not sufficiently familiar with their approach.}

\bibliographystyle{plain}
\bibliography{traits}

\end{document}
