\documentclass[11pt,oneside]{report}
\usepackage[a4paper, total={6.5in, 9in}]{geometry}
\usepackage{url}
\usepackage{listings}
\usepackage{listings-rust}
\usepackage[scaled=0.82]{beramono}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage[title]{appendix}
\usepackage{mathpazo}
%\usepackage{mathptmx}
\usepackage{array}
\usepackage{booktabs}
\usepackage{tablefootnote}
\usepackage[autostyle]{csquotes}
\usepackage[
	backend=biber, 
	bibstyle=numeric,
	citestyle=numeric, 
	sorting=nyt,
	sortcites=true, 
	abbreviate=false, 
	defernumbers=true,
]{biblatex}
\defbibheading{bibempty}{}

\addbibresource{traits.bib}

\newcolumntype{R}[1]{>{\raggedleft\arraybackslash}p{#1}} 
\newcolumntype{L}[1]{>{\raggedright\arraybackslash}p{#1}} 
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}

\newcommand{\code}[1]{{\selectfont\ttfamily{#1}}}

\lstdefinelanguage{LFortran}[]{Fortran}{
  morekeywords={abstract,import,type,class,extends,auto,deferred,
                implements,sealed,pass,associate,generic}
}

\hypersetup{
    colorlinks,
    linkcolor={blue!70!black},
    citecolor={blue!70!black},
    urlcolor={blue!70!black}
}

\frenchspacing

\begin{document}

\title{\textbf{A traits system for the uniform expression of run-time
       and compile-time polymorphism in Fortran}}

\author{Konstantinos Kifonidis, Ondrej Certik, Derick Carnazzola}

\maketitle

\abstract{Based on conclusions drawn from a survey of modern
  languages, a traits system for Fortran is developed that is fully
  backwards compatible with the present Fortran language, and allows
  for the uniform management of source code dependencies on both
  user-defined and language-intrinsic types via run-time and
  compile-time polymorphism. The feature set that is described here is
  small enough to facilitate a first prototype implementation in an
  open source compiler, like LFortran, or LLVM Flang, but at the same
  time comprehensive enough to already endow Fortran with polymorphism
  capabilities that equal those of modern programming languages like
  Swift, Rust, Go, or Carbon. The discussed extensions allow for
  modern-day, traits-based, object-oriented programming, and powerful,
  easy to use, fully type-checked, generics. The latter support
  seamlessly both the procedural, functional, and object-oriented
  programming styles, and they largely get by \emph{without} requiring
  manual instantiations by the user. The presented design can also be
  naturally extended in the future to support rank-genericity for
  arrays, and compile-time polymorphic union/sum types. The new
  capabilities are expected to transform the way both Fortran
  applications and libraries will be written in the future. Decoupled
  software plugin architectures with enormously improved source code
  flexibility, reusability, maintainability, and reliability will
  become possible, without any need for run-time type inspections, and
  without any loss in computational performance.}

\chapter{Introduction}

Polymorphism was discovered in the 1960ies by Kristen Nygaard and
Ole-Johan Dahl during their development of Simula~67, the world's
first object-oriented (OO) language \cite{Dahl_04}. Their work
introduced into programming what is nowadays known as ``virtual method
table'' (i.e. function-pointer) based run-time polymorphism, which is
both the first focus of this document, and the decisive feature of all
OO languages. Several other forms of polymorphism are known today, the
most important of them being parametric polymorphism
\cite{Cardelli_Wegner_85}, also known as ``generics'', which is the
second focus of this document, and which has historically developed
disjointly from run-time polymorphism since it makes use of
compile-time mechanisms.


\section{The purpose of polymorphism}

But what is the purpose of polymorphism in a programming language?
What is polymorphism actually good for? One of the more comprehensive
answers to this question was given by Robert C. Martin in numerous
books (e.g. \cite{Martin_17}), as well as in the following quotation
from his blog \cite{Martin_14}:

\begin{displayquote}
``There really is only one benefit to polymorphism; but it's a big
  one. It is the inversion of source code and run time dependencies.

  In most software systems when one function calls another, the
  runtime dependency and the source code dependency point in the same
  direction. The calling module depends on the called module. However,
  when polymorphism is injected between the two there is an inversion
  of the source code dependency. The calling module still depends on
  the called module at run time. However, the source code of the
  calling module does not depend upon the source code of the called
  module. Rather both modules depend upon a polymorphic
  interface.

  This inversion allows the called module to act like a
  plugin. Indeed, this is how all plugins work.''
\end{displayquote}

Notice the absence of the words ``code reuse'' in these statements.
The purpose of polymorphism, according to Martin, is the ``inversion''
(i.e. replacement, or management) of rigid source code dependencies by
means of particular abstractions, i.e. polymorphic interfaces (or
protocols/traits, as they are also known today). The possibility to
reuse code is then merely the logical consequence of such proper
dependency management in a polymorphism-based software plugin
architecture.

\section{Source code dependencies in statically typed languages}

Which then are the source code dependencies that polymorphism helps us
manage? It has been customary to make the following distinction when
answering this question:
\begin{itemize}
\item
  Firstly, most larger programs that are written in statically typed
  languages (like Fortran) have dependencies on \emph{user-defined}
  procedures and data types. If the programmer employs encapsulation
  of both a program's procedures and its data, i.e. its state, both
  these dependencies can actually be viewed as dependencies on
  user-defined abstract data types. These are the dependencies that
  Martin is concretely referring to in the above quotation, and it is
  these dependencies on (volatile) user-defined data and
  implementations that are particularly troublesome, because they lead
  to rigid coupling between the various different \emph{parts} of an
  application. Their results are recompilation cascades, the
  non-reusability of higher-level source code units, the impossibility
  to comprehend a large application incrementally, and fragility of
  such an application as a whole.
\item
  Secondly, every program, that is written in a statically typed
  language, also has dependencies on abstract data types that are
  provided by the language itself. Fortran's \code{integer},
  \code{real}, etc. intrinsic types are examples of
  \emph{language-intrinsic} abstract data types. While hard-wired
  dependencies on such intrinsic types do not couple different parts
  of a program (because the implementations of these types are
  supplied by the language), they nevertheless make a program's source
  code rigid with respect to the data that it can be used on.
\end{itemize}

The most widely used approaches to manage dependencies on
language-intrinsic types have so far been through generics, while
dependency management of user-defined (abstract data) types has so far
been the task of OO programming and OO design patterns. Martin
\cite{Martin_17} has, for instance, defined object-orientation as
follows:

\begin{displayquote}
  ``OO is the ability, through the use of polymorphism, to gain
  absolute control over every source code dependency in [a software]
  system. It allows the architect to create a plugin architecture, in
  which modules that contain high-level policies are independent of
  modules that contain low-level details. The low-level details are
  relegated to plugin modules that can be deployed and developed
  independently from the modules that contain high-level policies.''
\end{displayquote}

\section{Modern developments}

Notice how Martin's modern definition of object-orientation, that
emphasizes source code decoupling, is the antithesis to the usually
taught ``OO'' approaches of one class rigidly inheriting
implementation code from another. Notice also how his definition does
not require some specific type of polymorphism for the task of
dependency management, as long as (according to Martin's first
quotation) the mechanism is based on polymorphic interfaces.

Martin's statements on the purpose of both polymorphism and OO simply
reflect the two crucial developments that have taken place in these
fields over the last decades. Namely, the realizations that
\begin{itemize}
\item
  run-time polymorphism should be freed from the conflicting concept
  of implementation inheritance (to which it was originally bound
  given its Simula~67 heritage), and be formulated exclusively in
  terms of conformance to polymorphic interfaces, i.e. function
  signatures, or purely procedural abstractions, and that
\item
  compile-time polymorphism should be formulated in exactly the same
  way as well.
\end{itemize}

These two developments, taken together, have recently opened up the
possibility to treat polymorphism, and hence the dependency management
of both user-defined and language-intrinsic types, uniformly in a
programming language. As a consequence, it has become possible to use
the potentially more efficient (but also less flexible) mechanism of
compile-time polymorphism also for certain tasks that have
traditionally been reserved for run-time polymorphism (in the form of
OO programming), and to mix and match the two polymorphism types
inside a single application to better satisfy a user's needs for both
flexibility and efficiency.

\section{Historical background}

The road towards these realizations was surprisingly long. Over
the last five decades, a huge body of OO programming experience first
had to demonstrate that the use of (both single and multiple)
implementation inheritance breaks encapsulation in OO languages, and
therefore results in extremely tightly coupled, rigid, fragile, and
non-reusable code. This led to an entire specialized literature on OO
design patterns \cite{Gamma_et_al_94,Martin_03,Holub_04}, that aimed
at avoiding such rigidity by replacing the use of implementation
inheritance with the means to formulate run-time polymorphism that are
discussed below. It also led to the apprehension that implementation
inheritance (but \emph{not} run-time polymorphism) should be abandoned
\cite{Weck_Szyperski}. In modern languages, implementation inheritance
is either kept solely for backwards compatibility reasons (e.g. in the
Swift and Carbon languages), or it is foregone altogether (e.g. in
Rust, and Go).

The first statically typed mainstream programming language that
offered a proper separation of run-time polymorphism from
implementation inheritance was Objective~C. It introduced
``protocols'' (i.e. polymorphic interfaces) in the year 1990
\cite{Cox_et_al_20}. Protocols in Objective C consist of pure function
signatures, that lack implementation code. Objective~C provided a
mechanism to implement multiple such protocols by a class, and to thus
make classes conform to protocols. This can be viewed as a restricted
form of multiple inheritance, namely inheritance of object
\emph{specification}, which is also known as \emph{subtyping}. Only a
few years later, in 1995, the Java language hugely popularized these
ideas using the terms ``interfaces'' and ``interface inheritance''
\cite{Cox_et_al_20}. Today, nearly all modern languages support
polymorphic interfaces/protocols, and the basic mechanism of multiple
interface inheritance that was introduced to express run-time
polymorphism in Objective~C, often in even improved, more flexible,
manifestations. The only negative exceptions in this respect being
modern Fortran, and C++, which both still stick to the obsolescent
Simula~67 paradigm.

A similarly lengthy learning process, as that outlined for run-time
polymorphism, took also place in the field of compile-time/parametric
polymorphism. Early attempts, notably templates in C++, to render
function arguments and class parameters polymorphic, did not impose
any constraints on such arguments and parameters, that could be
checked by C++ compilers. With the known results on compilation times
and cryptic compiler error messages
\cite{Haveraaen_et_al_19}. Surprisingly, Java, the language that truly
popularized polymorphic interfaces in OO programming, did not provide
an interface based mechanism to constrain its generics. Within the
pool of mainstream programming languages, this latter realization was
only made with the advent of Rust \cite{Matsakis_2014}.

Rust came with a traits (i.e. polymorphic interfaces) system with which
it is possible for the user to uniformly and transparently express
both generics (i.e. compile-time) and run-time polymorphism in the
same application, and to relatively easily switch between the two,
where possible. Rust's traits are an improved form of
protocols/interfaces in that the user can implement them for a type
without having these implementations be coupled to the type's actual
definition. Thus, existing types can be made to retroactively
implement new traits, and hence be used in new settings (with some
minor restrictions on user ownership of either the traits or the
types).

Rust's main idea was quickly absorbed by almost all other mainstream
modern languages, most notably Swift, Go, and Carbon, with the
difference that these latter languages tend to leave the choice
between static and dynamic binding of procedures to the compiler, or
language implementation, rather than the programmer. C++ is in the
process of adopting generics constraints for its ``templates'' under
the term ``strong concepts'', but without implementing the greater
idea to uniformly express \emph{all} the polymorphism in the language
through them. An implementation of this latter idea must today be
viewed as a prerequisite in order to call a language design
``modern''. The purpose of this document is to describe additions to
Fortran, that aim to provide the Fortran language with such modern
capabilities.

\chapter{Case study: Calculating the average value of a numeric array}

To illustrate the advanced features and capabilities of some of the
available modern programming languages with respect to polymorphism,
and hence dependency management, we will make use here of a case
study: the simple test problem of calculating the average value of a
set of numbers stored inside a one-dimensional array. In the remainder
of this chapter, we will first provide an account and some
straightforward monomorphic (i.e. rigidly coupled) functional
implementation of this test problem, followed by a functional
implementation that makes use of both run-time and compile-time
polymorphism to manage rigid source code dependencies. In the survey
of programming languages presented in Chapter~\ref{chapt:survey}, we
will then recode this standard test problem in an encapsulated
fashion, to highlight how the source code dependencies in this problem
can be managed in different languages even in more complex situations,
that require OO techniques.

\section{Monomorphic functional implementation}
\label{sect:mono_functional}

We have chosen Go here as a language to illustrate the basic ideas.
Go is easily understood, even by beginners, and is therefore well
suited for this purpose (another good choice would have been the Swift
language). The code in the following Listing~\ref{lst:funcGo} should
be self explanatory for anyone who is even only remotely familiar with
the syntax of C family languages. So, we'll make only a few remarks
regarding syntax.
\begin{itemize}
\item
  While mostly following a C like syntax, variable declarations in Go
  are essentially imitating Pascal syntax, where a variable's name
  precedes the declaration of the type.
\item
  Go has two assignment operators. The usual \code{=} operator, as it
  is known from other languages, and the separate operator \code{:=}
  that is used for combined declaration and initialization of a
  variable.
\item
  Go has array slices that most closely resemble those of Python's
  Numpy (which exclude the upper bound of an array slice).
\end{itemize}

Our basic algorithm for calculating the average value of an array of
integer elements employs two different implementations for
averaging. The first makes use of a ``simple'' summation of all the
array's elements, in ascending order of their array index. While the
second sums in a ``pairwise'' manner, dividing the array in half to
carry out the summations recursively, and switching to the ``simple''
method once subdivision is no longer possible. In both cases, the
resulting sum is then divided by the array's number of elements, to
obtain the desired average.

\lstinputlisting[language=Go,style=boxed,label={lst:funcGo},caption={Monomorphic functional version of the array averaging example in Go.}]{Code/Go/coupled.go}

An inspection of Listing~\ref{lst:funcGo} will readily reveal that
this code has three levels of rigid (i.e. hard-wired)
dependencies. Namely,
\begin{enumerate}
\item
  function \code{pairwise\_sum} depending on function
  \code{simple\_sum}'s implementation,
\item
  functions \code{simple\_average} and \code{pairwise\_average}
  depending on functions' \code{simple\_sum}, and \code{pairwise\_sum}
  implementation, respectively, and
\item
  the entire program depending rigidly on the \code{int32} data type in
  order to declare both the arrays that it is operating on, and
  the results of its summation and averaging operations.
\end{enumerate}
The first two items are dependencies on user-defined implementations,
while the third is a typical case of rigid dependency on a
language-intrinsic type, which renders the present code incapable of
being applied to arrays of any other data type than
\code{int32}s. Given that we are dealing with three levels of
dependencies, three levels of polymorphism will accordingly be
required to remove all these dependencies.


\section{Polymorphic functional implementation}
\label{sect:poly_functional}

Listing~\ref{lst:polyfuncGo} gives an implementation of our test
problem, that employs Go's generics and functional features in order
to eliminate the last two of the rigid dependencies that were listed
in Sect.~\ref{sect:mono_functional}. The code makes use of Go's
generics to admit arrays of both the \code{int32} and \code{float64}
types as arguments to all functions, and to express the return values
of the latter. It also makes use of the run-time polymorphism inherent
in Go's functional features, namely closures and variables of
higher-order functions, to replace the two previous versions of
function \code{average} (that depended on specific implementations),
by a single polymorphic version. Only the rigid dependency of function
\code{pairwise\_sum} on function \code{simple\_sum} has not been
removed, in order to keep the code more readable. In the OO code
versions, that will be presented in Chapter~\ref{chapt:survey}, even
this dependency is eliminated.

A few remarks are in order for a better understanding of
Listing~\ref{lst:polyfuncGo}'s code:
\begin{itemize}
\item
  In Go, generic type parameters to a function, like the parameter
  \code{T} here, are provided in a separate parameter list, that is
  enclosed in brackets [ ].
\item
  Generic type parameters have a constraint that follows their
  declared name. Go exclusively uses interfaces as such constraints
  (like the interface \code{INumeric} in the following code).
\item
  Interfaces consist of either explicit function signatures, or
  \emph{type sets}, like ``\code{int32 | float64}'' in the present
  example. The latter actually signify a set of function signatures,
  too, namely the signatures of the intersecting set of all the
  operations and intrinsic functions for which the listed types
  provide implementations.
\item
  The code makes use of type conversions to the generic type \code{T},
  where required. For instance, \code{T(0)} converts the constant
  \code{0} to the corresponding zero constant of type \code{T}.
\item
  The code instantiates closures and stores these by value in two
  variables named \code{avi} and \code{avf} for later use (Fortran
  and C programmers should note that \code{avi} and \code{avf} are
  \emph{not} function pointers!).
\end{itemize}


\lstinputlisting[language=Go,style=boxed,label={lst:polyfuncGo},caption={Polymorphic functional version of the array averaging example in Go.}]{Code/Go/functional.go}

Notice how, in order to instantiate the closures \code{avi} and
\code{avf} (see the \code{switch} statement), manual instantiations of
the \code{simple\_sum} and \code{pairwise\_sum} generic functions are
required -- with the arguments \code{int32} or \code{float64} being
substituted for the generic type parameter, \code{T}, of these
functions.

The motivation to code the example as in Listing~\ref{lst:polyfuncGo}
is that once the two closures, \code{avi} and \code{avf}, have been
properly instantiated, they may then be passed from the main program
to any other client code that may need to make use of the particular
averaging algorithm that was selected by the user. This latter client
code would \emph{not} have to be littered with \code{switch}
statements itself, and it would \emph{not} have to depend on any
specific implementations. It would merely depend on the closures'
interfaces. The same holds for the OO code versions that are discussed
in the next chapter, with objects replacing the closures (both being
merely slightly different realizations of the same idea).

\chapter{Survey of modern languages}
\label{chapt:survey}

In the present chapter, we give encapsulated (i.e. OO) code versions
of the test problem in various modern languages. As in the functional
code version presented in Sect.~\ref{sect:poly_functional}, we employ
run-time polymorphism to manage the dependencies on user-defined
implementations (in this case abstract data types), and generics in
order to manage the dependencies on language-intrinsic types. This
serves to illustrate how both run-time and compile-time polymorphism
can be typically used for dependency management in an OO setting in
these modern languages. The survey also aims to highlight the many
commonalities but also some of the minor differences in the approaches
to polymorphism that were taken in these different languages. As a
final disclaimer, we do not advocate to code problems in an OO manner
that can be easily coded in these languages in a functional way (as it
is the case for this problem). However, in more complex cases, where
many more nested functions would need to be used, and where state
would have to be hidden, the OO programming style would be the more
appropriate one. Hence, our test problem will stand in, in this
chapter, for emulating such a more complex problem, that would
benefit from an encapsulated coding style.


\section{Go}

Go has supported run-time polymorphism through (polymorphic)
``interfaces'' (and thus modern-day OO programming) since its
inception. In Go, encapsulation is done by storing state in a
``\code{struct}'' and by binding procedures, that need to use that
state, to this same \code{struct}. Thereby creating a user-defined
abstract data type (or ADT) with methods. Go allows the programmer to
implement multiple polymorphic interfaces for such a type (i.e. to use
multiple interface inheritance), even though it offers no explicit
language statement for this purpose.

Instead, a user-defined type is implicitly assumed to implement an
interface whenever it provides implementations of all the interface's
function signatures. This way of implementing interfaces requires only
an object reference of the type to be passed to its methods (by means
of a separate parameter list, in front of a method's actual name). It
is otherwise decoupled from the type's (i.e. the ADT's \code{struct})
definition. Go, finally, makes it explicit in its syntax that
interfaces (like \code{struct}s) are types in their own right, and
that hence polymorphic variables (i.e. objects) can be declared in
terms of them.

Restrictions in Go are that language-intrinsic types cannot have
user-provided methods, and that methods and interfaces cannot be
directly implemented for user-defined types whose definitions are
located in other packages. That is, the programmer has to write
wrappers in the latter case.

Since version 1.18, Go also supports compile-time polymorphism through
generics. Go's generics make use of ``strong concepts'', since they
are bounded by constraints that are expressed through
interfaces. Hence, the Go compiler will fully type-check generic code.
In Go, structures, interfaces, and functions, but not methods, can all
be given their own generic type parameters.

\subsection{Encapsulated version coded in Go}
\label{sect:Go_encapsulated}

Listing~\ref{lst:OOGo} gives an encapsulated version of the test
problem coded in Go. The two different implementations of the
\code{sum} function have been encapsulated in two different ADTs named
\code{SimpleSum} and \code{PairwiseSum}, whereas a third ADT named
\code{Averager} encapsulates the functionality that is required to
perform the actual averaging. The latter two ADTs contain the
lower-level objects \code{other} and \code{drv} of \code{ISum[T]} type
as components, to which they delegate calls to these objects'
\code{sum} methods. Notice, how the use of the polymorphic interface
\code{ISum[T]} for the declarations of the objects \code{other} and
\code{drv} enables either \code{SimpleSum} or \code{PairwiseSum}
instances to be plugged into these objects' clients.

A second interface, named \code{IAverager}, is used to enable
polymorphism for different averaging algorithms. Finally, there's a
third interface, \code{INumeric}, that serves exactly the same purpose
as in the functional polymorphic version that was given in
Sect.~\ref{sect:poly_functional}, namely to make all function
arguments and return values polymorphic, by admitting as input and
output parameters both the \code{int32} and \code{float64} intrinsic
types.

Hence, three polymorphic interfaces were required in this code, in
order to eliminate the three levels of rigid dependencies that were
listed in Sect.~\ref{sect:mono_functional}. Notice also that,
exempting \code{INumeric}, all the interfaces and all the user-defined
ADTs need to take in generic type parameters in this example. In Go,
this is required in order to enable all the \code{sum} and
\code{average} methods to use generic type parameters.

\lstinputlisting[language=Go,style=boxed,label={lst:OOGo},caption={Encapsulated Go version of the array averaging example.}]{Code/Go/mixed.go}

The main program makes use of Go's built-in structure constructors,
and chaining of their calls, in order to instantiate objects of the
required ADTs. In particular, it instantiates run-time polymorphic
\code{Averager} objects (depending on whether simple or pairwise sum
averaging is to take place), and it does so for both the \code{int32}
and \code{float64} types separately, in order to then use these
objects on \code{int32} and \code{float64} data, respectively. That
\code{two} such objects are required (one for each language-intrinsic
data type) is connected to the aforementioned fact that in order to
make methods use generic type parameters in Go, one has to parameterize
interfaces, and instantiate these with different actual data types, as
in \code{func main}'s first two code lines. A single
(i.e. unparameterized) \code{IAverager} interface therefore doesn't
suffice, which is unfortunate from the user's perspective, as some
code duplication in client code cannot be avoided in this way.

\section{Rust}

Like Go, Rust supports both run-time and compile-time polymorphism
through polymorphic interfaces, which Rust calls ``traits''. Unlike
Go, Rust has its programmers implement traits in a nominal manner,
by using explicit ``\code{impl}'' code blocks to provide a trait's
method implementations. These same \code{impl} blocks also serve to
bind methods to a type that aren't a part of some trait, like
e.g. user-defined constructors for \code{struct}s (see the functions
named ``\code{new}'' in the following code Listing~\ref{lst:OORust}).

In contrast to Go, Rust allows the programmer to implement traits for
both user-defined \emph{and} language-intrinsic types, and to do so
for types that are located in external libraries (called ``crates'' in
Rust), as long as the traits themselves are defined in the
programmer's own crate. The reverse, namely implementing an external
trait for a user-owned type, is also possible. Only the (edge) case of
implementing an external trait for an external type is not allowed
(this is called the ``orphan rule'' \cite{Klabnik_Nichols}). The
latter case requires the use of wrappers.

Comparable to Go, Rust's generics model allows for the generic
parameterization of functions, traits, and user-defined types like
\code{struct}s. Rust does not explicitly forbid generic
methods. However, if one defines such a method's signature within a
trait, then this will make the trait unusable for the declaration of
any ``trait objects'' \cite{Lyon}, i.e. for the employment of run-time
polymorphism. Thus, the Rust programmer will in general (need to)
parameterize traits and \code{struct}s rather than any methods
themselves. Rust generics are fully type-checked at compilation time,
i.e. Rust supports ``strong concepts''.

\subsection{Encapsulated version coded in Rust}

The encapsulated Rust version of our test problem that is given in the
following Listing~\ref{lst:OORust} is in its outline quite similar to
the corresponding Go version. There are, however, a few minor
differences, that are listed in the following notes.

\begin{itemize}
\item
  Rust uses angled brackets, \code{< >}, to indicate generic parameter
  lists.
\item
  Generics constraints in Rust are typically enforced by specifying
  the required traits in \code{impl} blocks using \code{where}
  statements.
\item
  Use of a ``\code{Num}'' trait from the external ``\code{num}'' crate was
  necessary, in order to enable numeric operations on generic types,
  which leads to dependency on external library code.
\item
  At times, use of the ``\code{Copy}'' trait also had to be made, to
  work around Rust's default move semantics.
\item
  In order to help make all of the source code dependencies explicit,
  our Rust version employs modules, and \code{use} statements to import
  the required functionality.
\item
  Despite reliance on external dependencies, conversion to generic
  types wasn't possible. This led to the necessity to move a type
  conversion, that in the Go implementation was included in the code
  of method \code{average}, to this method's calls in the main
  program. We also had to import a \code{zero} generic function from
  the external \code{num} crate, in order to initialize the variable
  \code{s} that is returned by the \code{sum} method of the
  \code{SimpleSum} ADT.
\item
  Rust's default structure constructors suffer from the same flaw as
  Fortran's. That is, they are unable to initialize from an external
  scope, structure components that are declared being private to their
  module. As in Fortran, use of user-defined constructors must be made
  instead (see the functions named \code{new} that are defined in
  separate \code{impl} blocks for the ADTs \code{PairwiseSum} and
  \code{Averager}).
\item
  To declare run-time polymorphic variables one has to put so-called
  ``trait objects'' into ``Boxes'', i.e. to declare smart pointers of
  them, for dynamic instantiation and memory allocation (this is the
  Rust equivalent to using \code{allocatable} polymorphic objects in
  Fortran).
\end{itemize}

\lstinputlisting[language=Rust,style=boxed,label={lst:OORust},caption={Encapsulated Rust version of the array averaging example.}]{Code/Rust/mixed_poly/src/main.rs}

The main program in the Rust version is somewhat longer than in the
corresponding Go version because of the need to import dependencies
from modules (as it would be necessary in realistic situations). Its
logic is also somewhat convoluted compared to the Go version, because
Rust doesn't allow the programmer to declare variables that aren't
initialized upon declaration, and because of the aforementioned
necessity to move the required type conversions out of method
\code{average}, and into the calls of this method. Otherwise the codes
are pretty much identical\footnote{Notice that the present Rust
version makes universal use of dynamic method dispatch via trait
objects, in order to correspond most closely to all the other
implementations that we provide in both the present chapter, and in
Sect.~\ref{sect:Fortran_dynamic_dispatch}. An alternative, more
idiomatic, Rust version that is equivalent to the Fortran version
which we give in Sect.~\ref{sect:Fortran_static_dispatch}, and that
effects static dispatch of the various \code{sum} methods through the
use of generics, can be found in the \code{Code} subdirectory that is
accompanying this document.}.


\section{Swift}
\label{sect:Swift}

Being a successor language to Objective~C, Swift differs slightly from
the languages considered so far in that it opted to retain
implementation inheritance for backwards compatibility to Objective~C,
whereas both Go and Rust do not support implementation inheritance
\emph{by design}. Swift therefore supports ``classical'' classes, but
it also allows one to bind methods to structures (which, in contrast
to classes, are value types in Swift).

Like Go and Rust, Swift (furthermore) supports a traits system in order
to implement both run-time and compile-time polymorphism through
polymorphic interfaces, that are called ``protocols'' in Swift. If the
Swift programmer chooses to ignore implementation inheritance and
classes, he can therefore very much program with structures and
protocols in Swift as he would with structures and interfaces/traits
in Go and Rust, respectively.

Given Swift's backwards compatible design, implementation of a
protocol (i.e. interface inheritance) is usually done as in classical
OO languages, i.e. within a structure's or a class's definition. A
colon (\code{:}) followed by one or more interface names must be
supplied for this purpose after the structure's or class's own
name. However, a very powerful facility for types to implement
protocols retroactively is also provided, through so-called
\code{extension}s, that work even if the types' source code is
inaccessible (because one is, e.g., working with a library in binary
form). This same facility also allows for protocols to be implemented
by language-intrinsic types. For instance, the following little
program, given by Listing~\ref{lst:extSwift}, prints out ``\code{I am
  4.9}''.
\lstinputlisting[language=Swift,style=boxed,label={lst:extSwift},caption={Swift
    example of implementing a protocol for an intrinsic data
    type.}]{Code/Swift/extension.swift}

Swift generics support ``strong concepts'', and are thus fully
type-checked at compile time, and their capabilities are on par with
those of Go and Rust. In one aspect they are even superior, namely in
that Swift allows for parameterized \emph{methods}, instead of
parameterized protocols. This has some interesting, positive
implications for the Swift programmer, that will be discussed in
detail below.

\subsection{Encapsulated version coded in Swift}

Listing~\ref{lst:OOSwift} gives an example of how the encapsulated
version of the array averaging test problem can be programmed in
Swift. See the following remarks in order to understand this code:

\begin{itemize}
  \item
    Swift uses angled brackets to indicate generic parameter
    lists.
  \item
    Generic type constraints are formulated by supplying a protocol
    name after a type parameter (separated by a colon).
  \item
    Swift does not supply an equivalent to Go's \code{int32 | float64}
    syntax and semantics. Hence the user must use a \code{Numeric}
    protocol that is defined by the standard library, as a constraint for
    numeric types. Which leads to reliance on library code.
  \item
    Unfortunately, Swift's \code{Numeric} protocol does \emph{not} support
    the division operation! Hence the division that would have been required
    in function \code{average} of the \code{Averager} ADT had to be moved
    out to the calling code of the main program.
  \item
    The Swift version makes use of language built-in, default, structure
    constructors (called ``initializers'').
  \item
    Array slices are not arrays themselves. Hence, an explicit conversion
    using an \code{Array()} constructor is required in such cases.
  \item
    By default, function and method calls in Swift make use of keyword
    arguments.
  \item
    The syntax for type conversion into a generic type \code{T} is
    somewhat peculiar. E.g. Go's \code{T(0)} is written as
    \code{T(exactly:0)!} in Swift (making use of the mandatory keyword
    ``\code{exactly}'' in the function responsible for the type
    conversion).
\end{itemize}

\lstinputlisting[language=Swift,style=boxed,label={lst:OOSwift},caption={Encapsulated Swift version of the array averaging example.}]{Code/Swift/mixed.swift}

Even a casual glance at the Swift version will show that the Swift
code is the easiest to read and understand among the encapsulated
implementations that were presented in this chapter. This is largely
the result of Swift supporting generic methods, and hence not
requiring the programmer to parameterize and instantiate any generic
interfaces (protocols), in contrast to both Go and Rust. The
consequences are
\begin{itemize}
\item
that method genericity for an ADT's objects can be expressed using
only a single, as opposed to multiple protocols,
\item
that therefore merely a \emph{single} object instance of that same
protocol is required, in order to be able to operate on many different
language-intrinsic data types, and
\item
that this also (largely) \emph{obviates the need for manual
instantiations of generics in Swift} (because generic
functions/methods are easier to instantiate automatically by the
compiler, as it can almost always infer the required types by checking
the regular arguments that are passed to a function/method)!
\end{itemize}

As an example, consider the object \code{av} in the above Swift code
that contains the functionality for array averaging. This object
supports two different levels of polymorphism: Firstly, given that it
is an instance of the \code{IAverager} protocol, it can be
polymorphically assigned different averaging algorithms (see the
\code{switch} statement). Secondly, because it contains an
\code{average} method that is generic, it can be used on data of
different intrinsic types, like \code{Int32} and \code{Float64} here.

Notice that the main Swift program needs to declare merely a
\emph{single} such object variable of \code{IAverager} type, to make use of
all these capabilities. This is a direct consequence of there being
only a single (i.e. unparameterized) version of the \code{IAverager}
protocol, and of parameterizing the protocol's method signatures by
generic types rather than the protocol itself.

Contrast this with Go's and Rust's model, where not only separate
objects of \code{IAverager} type are required for \emph{every}
different intrinsic data type that the programmer wishes to use these
objects with. But where also \emph{manual} instantiations of
corresponding versions of the generically parameterized
\code{IAverager} interface/trait are required from the programmer, for
declaring these objects.

Swift's generics model gets rid of all of that complexity, and
therefore vastly simplifies client code. We consider this a very
significant advantage of the generics approach that is taken in Swift
vs. that of Go and Rust.


\section{Conclusions}

The use of run-time polymorphism by means of (polymorphic) interfaces
is rather similar in all the languages considered here. The most
significant differences (that were not concretely explored here)
appear to be that Go has stricter limitations on retroactively
implementing interfaces for existing types than the other
languages. Whereas Rust (with some minor restrictions), and Swift
allow the implementation of an interface by some type to be
accomplished independently from the type's definition site. Rust and
Swift thereby overcome Haveraaen et al.'s critique
\cite{Haveraaen_et_al_19} of Java regarding this point. In fact, it is
\emph{interface inheritance} which makes the uniform polymorphic
treatment of both intrinsic and user-defined types possible in the
first place in Rust and Swift, that Haveraaen et al. seem to also
(rightly) demand. All the considered languages are also very similar
in that they support fully type checked generics via the mechanism
of interfaces. In the following, we will thus only summarize the most
significant differences in these languages' generics features.

\subsection{Go}

Go's basic model to implement generics allows structures, interfaces,
and ordinary functions, but not methods, to be given their own generic
type parameters. The lack of true generic methods makes some
duplication of instantiation code in clients
unavoidable. Nevertheless, generic Go code is quite easy to read and
to understand. What sets Go apart from the other languages is its
built-in, easy to use support for conversion to generic types, and
especially its brilliant new notion to interpret type sets as
interfaces, along with its syntax to support this notion. This enables
the Go programmer to easily tailor constraints on generic types to his
specific needs, which is what makes the use of generics in Go
pleasant. We consider these latter particular features of Go as ``must
haves'' for Fortran.

\subsection{Rust}

Rust's basic model for generics is similar to Go's in that it allows
for parameterization of structures, interfaces, and ordinary
functions, but not necessarily methods. Hence, what has been said
above for Go in this respect holds also for Rust. Rust has,
unfortunately, some quirks which render its use for the management of
all types of dependencies through polymorphism somewhat sub-optimal
when compared to the other languages considered here. The language is
unpleasant to use, because of its ``borrow checker'', its employment
of move semantics by default, its \emph{excessive} obsession with type
safety, and its overall C++-like philosophy to copiously rely on
external dependencies, even for the most basic tasks, like
initializing a generic type. The Rust version of our test case is
therefore marred by some dependencies on external libraries, which is
quite contrarian to the purpose of programming in a polymorphic
fashion, namely to avoid rigid dependencies. But even with the
functionality provided by such external dependencies, Rust doesn't
allow type conversion to generic types within generic routines. A
necessary capability for numerical work that is, for instance, built
into Go. The points we like most about the language are its idea to
decouple trait implementations from a \code{struct}'s definition
through explicit \code{impl} blocks, and the complete control over the
use of dynamic vs. static method dispatch (via trait objects and
generics, respectively) that Rust affords the programmer. These are
particular features of Rust that, in our opinion, Fortran should
borrow in some form.

\subsection{Swift}

Swift's basic model of implementing generics by allowing parameterized
structures, functions, and methods (but not parameterized interfaces)
is both the easiest to read, and the easiest to use from a
programmer's perspective. Swift's generics design allows the Swift
compiler to instantiate generics largely automatically, through type
inference of the regular arguments that are passed to functions,
methods, and (structure or class) constructors. In contrast to the
other languages, in Swift, the user almost never has to bother with
instantiating any generics.

If the Swift programmer knows how to write generic functions, his
knowledge automatically translates into coding generic methods, since
generic functions can be transformed into generic methods without
requiring changes to their function signatures. This property is
helpful for the refactoring of non-OO codes into corresponding OO
versions.

We hence consider Swift's generics to be the most attractive model to
base Fortran's basic generic capabilities on, provided that it can be
implemented sufficiently easily. The fact that Swift is a language
that does not put emphasis on numerics, and whose present standard
library therefore does not provide a truly useful \code{Numeric}
protocol (that supports all the usual numeric operations), is of
absolutely \emph{no} consequence for adopting Swift's basic generics
design for Fortran.

Fortran will necessarily do a better job in this respect, both by
borrowing Go's idea of formulating interfaces in terms of type sets,
so that the user can easily implement his own type constraints. But
also by making accessible to the user a set of language-built in
interfaces that are truly useful for a variety of numeric operations,
that are implemented by Fortran's intrinsic types.


\chapter{Fortran extensions I: Traits and types}

The present and the next chapter, describe a number of simple
extensions to Fortran, that we consider essential in order to enable
dependency management through polymorphism at a level of functionality
that is on par with modern languages like Swift, Rust, Go, or
Carbon. The present chapter adds general subtyping capabilities to
Fortran, while the next chapter aims at providing specific support for
generics. The extensions related to subtyping concern abstract
interfaces, derived types, and the class specifier for variable
declarations. They also encompass an extremely useful, new Fortran
feature: the \code{implements} statement.

\section{Named abstract interfaces (traits)}

The most important of all the following extensions is the capability
to define named abstract interfaces, or traits (i.e. named collections
of procedure signatures), in order to suitably constrain (and hence to
type-check) the declarations of polymorphic variables. Named abstract
interfaces are the crucial feature that is required in order to
uniformly and properly express both run-time and compile-time
polymorphism (i.e. modern-day OO and generic programming,
respectively) in the language, and to thereby enable a uniform
management of dependencies on both user-defined \emph{and}
language-intrinsic types.

\subsection{Definition}
\label{sect:interface_defs}

Fortran already allows the programmer to define unnamed abstract
interfaces. But in order to use these as traits, named versions of
them are required. As in the following example, that defines three
such named interfaces, \code{IAddable}, \code{ISubtractable}, and
\code{IPrintable} that are intended as abstract blueprints for actual
implementations of three type-bound procedures, named \code{add},
\code{sub}, and \code{output}, respectively:
\begin{lstlisting}[language=LFortran,style=boxed]
  abstract interface :: IAddable
     function add(self,other) result(res)
        deferred(self), intent(in) :: self, other
        deferred(self)             :: res
     end function add
  end interface IAddable

  abstract interface :: ISubtractable
     function sub(self,other) result(res)
        deferred(self), intent(in) :: self, other
        deferred(self)             :: res
     end function sub
  end interface ISubtractable

  abstract interface :: IPrintable
     subroutine output(self)
        deferred(self), intent(in) :: self
     end subroutine output
  end interface IPrintable
\end{lstlisting}

Notice, how in all these interfaces, the explicit passed-object dummy
argument, \code{self}, but also all the other arguments that need to
have the same type as \code{self}, are declared by means of the new
\code{deferred} declaration specifier for associated types. Here,
\code{deferred(self)} refers to the types that \code{self} can take on
in actual implementations of these interfaces. This is discussed in
more detail in Sect.~\ref{sect:assoc_types}. Since both named abstract
interfaces, and the new \code{deferred} declaration specifier, are
merely simple additions to Fortran, that aim to extend the present use
cases of abstract interfaces in the language (which currently serve as
bounds on the signatures of procedure pointers, and deferred,
i.e. abstract, methods), these new features are fully backwards
compatible with the present language.

\subsection{Associated (deferred) types}
\label{sect:assoc_types}

Associated types (which are also available in Swift and Rust, but in
contrast to Fortran are not required for the declaration of any
explicit passed-object dummy arguments in these languages) are
essentially aliases. They are employed within abstract
interfaces/traits in lieu of types, whose actual value is not known at
the time a trait is formulated, but will be known by a compiler once
the programmer has actually implemented that trait for some concrete
derived or intrinsic data type.

Consider, for instance, the interface \code{IPrintable} of
Sect.~\ref{sect:interface_defs}, and suppose that a user provides, in
his source code, an implementation of this interface/trait for some
derived type (that we shall assume here to be extensible by type
extension, and named \code{MyType}). Then the declaration
\begin{lstlisting}[language=LFortran,style=boxed]
  deferred(self), intent(in) :: self
\end{lstlisting}
of the passed-object dummy argument \code{self}, in \code{IPrintable}'s
signature of subroutine \code{output}, would need to be matched by a
declaration
\begin{lstlisting}[language=LFortran,style=boxed]
  class(MyType), intent(in) :: self
\end{lstlisting}
in the user's actual implementation of that subroutine. If the user
would need to implement \code{IPrintable} also for Fortran's
\code{real(real64)} type (see
Sect.~\ref{sect:implement_intrinsic_type} for the details of how this
can be accomplished), then that same declaration in \code{IPrintable}
would instead need to be matched by a declaration
\begin{lstlisting}[language=LFortran,style=boxed]
  real(real64), intent(in) :: self
\end{lstlisting}
in \code{output}'s implementation. Thus, \code{deferred(self)} serves
to stand in as an alias, in \code{IPrintable}, for both the
\code{class(MyType)}, and \code{real(real64)} types, that object
\code{self} takes on in subroutine \code{output}'s two different
implementations. Since the concept of an associated type only makes
sense within traits, the \code{deferred} declaration specifier for
associated types can, accordingly, only be used within named abstract
interfaces.

\subsection{Extends attribute}
\label{sect:extends_spec}

Abstract interface definitions must allow the programmer to define
new abstract interfaces that inherit procedure signatures from
\emph{multiple} simpler interfaces (multiple interface
inheritance). In the following example, the interface
\code{ICalculable} inherits the procedure signatures contained in both
the interfaces \code{IAddable}, and \code{ISubtractable}, making
\code{ICalculable} at the same time a \emph{subtype} of both these
simpler interfaces:
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface, extends(IAddable,ISubtractable) :: ICalculable
   end interface IBasicMath
\end{lstlisting}
That is, objects that implement (or adopt) the \code{ICalculable}
interface (i.e. conform to it), can also be used in settings that
require conformance to either the \code{IAddable}, or
\code{ISubtractable} interfaces.

The next example finally shows an interface, \code{IAdmissible}, that
both inherits a procedure signature, namely that of function
\code{add} which is contained in the \code{IAddable} interface, and
adds a second function signature of its own (which is named
\code{cast} here):
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface, extends(IAddable) :: IAdmissible  
      function cast(self,i) result(res)
         deferred(self), intent(in) :: self
         integer,        intent(in) :: i
         deferred(self)             :: res
      end function cast
   end interface IAdmissible 
\end{lstlisting}

\subsection{Generic overloading}
\label{sect:generic_stmt}

Named abstract interfaces support ``generic'' overloading of both
operators and procedures, with lists of (other) procedure names. This
is accomplished by making use, within such an interface, of the
\code{generic} statement that was introduced by Fortran 2018. The
following example shows how to overload, within the \code{IAdmissible}
interface of Sect.~\ref{sect:extends_spec}, Fortran's
\code{operator(+)} with the name of function \code{add}:
\begin{lstlisting}[language=LFortran,style=boxed]
  abstract interface, extends(IAddable) :: IAdmissible
     function cast(self,i) result(res)
        deferred(self), intent(in) :: self
        integer,        intent(in) :: i
        deferred(self)             :: res
     end function cast
     generic :: operator(+) => add
  end interface IAdmissible 
\end{lstlisting}
The effect of this is that any two objects, of some given type that
implements the \code{IAdmissible} interface, may be added using either
a direct call of their implemented \code{add} function, or an indirect
call of that function, via the overloaded \code{operator(+)}. See
Sect.~\ref{sect:types} for an actual example.

\section{Implements statement}
\label{sect:implements_stmt}

The language must allow not only for named abstract interfaces to
conform to other named abstract interfaces
(cf. Sect.~\ref{sect:extends_spec}), but also for both
language-intrinsic and user-defined types to do the same. That is, it
must be possible, for \emph{all} these types, to provide actual
implementations of procedures, whose signatures are contained within
named abstract interfaces. Moreover, this must be possible even
retroactively, that is without having to touch any original type
definitions. Otherwise, wrapper types would, in general, need to be
written, once an already defined type would need to implement some new
abstract interface (e.g. in cases where the original type definition
is inaccessible). All of this means that user-provided methods need to
be allowed also for \emph{language-intrinsic} types, and that the
provision of implementations must be possible regardless of any
original type definition site.

The \code{implements} statement, that is described in detail below,
provides these capabilities. This statement is modeled after the
``\code{extension}'' feature of Swift, where it is used to enable
retroactive implementation of new methods, additional constructors,
and especially new protocols/interfaces for types, in order to
\emph{dynamically} change a subtyping (i.e. interface inheritance)
hierarchy, and thus achieve utmost code flexibility. Swift's
\code{extension} blocks fulfill essentially the same purpose as Rust's
\code{impl} blocks. They have been slightly simplified here (for a
first implementation), and adjusted to Fortran's idiosyncracies and
syntax, that binds methods to types through declaration blocks, rather
than by including the actual implementation bodies themselves into
such a block (the implementations need to be supplied as module
procedures, as is usual in Fortran).

The syntax of the feature is symmetric to that of the \code{contains}
section of derived type definitions. That is, \code{implements}
statements make use of type-bound procedure declarations. The latter
have the same syntax, and make use of the same attributes
(\code{public}, \code{private}, \code{pass(arg-name)}, \code{nopass},
and \code{non\_overridable}), as type-bound procedure declarations in
derived type definitions. Merely the use of the \code{deferred}
attribute is not allowed. ``Generic'' type-bound procedure
declarations (as the Fortran standard calls them) can be used as
well. As a final disclaimer, notice that the \code{implements}
statement has absolutely \emph{no} relation to subclassing, i.e. one
derived type being extended into another through (rigid)
implementation inheritance. Rather, this is a feature that adds new
capabilities to a single, \emph{given} type.

\subsection{Adding methods to a type}
\label{sect:adding_methods}

The simplest use of the \code{implements} statement is to add some new
methods to a type. The following example shows how to add two methods,
named \code{add} and \code{sub}, to a derived type with name
\code{Calculable}, and how to provide their implementations as module
procedures:
\begin{lstlisting}[language=LFortran,style=boxed]
module basic
   ...
   type :: Calculable
      private
      real :: a
   end type Calculable

   implements :: Calculable
      procedure, public, pass(self) :: add, sub
   end implements Calculable

contains

   function add(self,other) result(res)
      class(Calculable), intent(in) :: self, other
      class(Calculable)             :: res
      res%a = self%a + other%a
   end function add

   function sub(self,other) result(res)
      class(Calculable), intent(in) :: self, other
      class(Calculable)             :: res
      res%a = self%a - other%a
   end function sub
   
end module basic      
\end{lstlisting}

\subsection{Implementing a trait}

Assume now, that the purpose of our addition of the previous two
methods was to actually make the \code{Calculable} type compatible
with settings where conformance to the \code{ICalculable} interface of
Sect.~\ref{sect:extends_spec} is required. So far, we have added the
code of the required methods, but we haven't made \code{Calculable}
pluggable yet into code that is written in terms of the
\code{ICalculable} interface. To fix this, we can simply acknowledge
(even from a different module, as in the following example), that the
\code{Calculable} type already has all of the required functionality
to implement the \code{ICalculable} interface:
\begin{lstlisting}[language=LFortran,style=boxed]
module enhanced
   ...  
   use basic, only: Calculable

   implements (ICalculable) :: Calculable
   end implements Calculable

end module enhanced
\end{lstlisting}

\subsection{Implementing multiple traits}
\label{sect:implementing_traits}

It is crucial, for flexibility, that the subtyping (i.e. interface
inheritance) mechanism, that is provided through the \code{implements}
statement, allow for a type to implement \emph{multiple} different
interfaces. For instance, if one wouldn't have defined the interface
\code{ICalculable}, and would nevertheless need to use objects of type
\code{Calculable} in settings that require conformance to either one
of the \code{IAddable} or \code{ISubtractable} interfaces of
Sect.~\ref{sect:interface_defs}, then the language must allow one to
acknowledge \code{Calculable}'s conformance to these interfaces using
a (comma-separated) list of names to the \code{implements} statement,
as follows:

\begin{lstlisting}[language=LFortran,style=boxed]
module enhanced
   ...  
   use basic, only: Calculable

   implements (IAddable,ISubtractable) :: Calculable
   end implements Calculable

end module enhanced
\end{lstlisting}

The last two examples have demonstrated how interfaces can actually be
implemented once their necessary method implementations were already
added to some type. Of course, it is also possible to do all of this
at one fell swoop, as in the following alternative example of the
aforegiven module \code{basic}:
\begin{lstlisting}[language=LFortran,style=boxed]
module basic
   ...
   type :: Calculable
      private
      real :: a
   end type Calculable

   implements (IAddable,ISubtractable) :: Calculable
      procedure, public, pass(self) :: add, sub
   end implements Calculable

contains

   function add(self,other) result(res)
      class(Calculable), intent(in) :: self, other
      class(Calculable)             :: res
      res%a = self%a + other%a
   end function add

   function sub(self,other) result(res)
      class(Calculable), intent(in) :: self, other
      class(Calculable)             :: res
      res%a = self%a - other%a
   end function sub

end module basic      
\end{lstlisting}
We could have also employed two separate \code{implements} statements, in
order to implement one interface at a time, like so
\begin{lstlisting}[language=LFortran,style=boxed]
module basic
   ...
   type :: Calculable
      private
      real :: a
   end type Calculable

   implements IAddable :: Calculable
      procedure, public, pass(self) :: add
   end implements Calculable

   implements ISubtractable :: Calculable
      procedure, public, pass(self) :: sub
   end implements Calculable
   
contains
   ...   
end module basic      
\end{lstlisting}
where we have skipped, for brevity, the implementation of the actual
methods, that would be done exactly as in the preceding example. The
effect would have been the same. Such splitting of \code{implements}
statements can be useful to improve code readability, as it makes the
association between the interfaces and the actual procedures, that are
to be implemented for any one of them, immediately obvious. These two
statements (together with the actual implementations), could then have
been distributed even among different modules and files. Notice, also,
how parentheses around interface lists in \code{implements} statements
are optional, but not required.

We finally wish to remark that in case the ``implementing'' type is an
\code{abstract} derived type, it must be allowed to provide an only
partial implementation of the interfaces that it adopts. However, any
non-abstract type that \code{extends} this abstract type through
subclassing (i.e. implementation inheritance) must then provide a full
implementation.

\subsection{Implementing a trait for an intrinsic type}
\label{sect:implement_intrinsic_type}

The \code{implements} statement can be used to provide methods, and to
implement traits, also for types that are \emph{intrinsic} to the
language -- much in the same fashion as it was already demonstrated for
derived types. The following listing shows how to code the Swift
example of Listing~\ref{lst:extSwift}, by implementing a single method
named \code{output}, that performs printouts for variable instances of
Fortran's \code{real(real64)} type:
\begin{lstlisting}[language=LFortran,style=boxed]
module real64_module

   use, intrinsic :: iso_fortran_env, only: real64

   abstract interface :: IPrintable
      subroutine output(self)
         deferred(self), intent(in) :: self
      end subroutine output
   end interface IPrintable

   implements IPrintable :: real(real64)
      procedure :: output
   end implements real(real64)

contains

   subroutine output(self)
      real(real64), intent(in) :: self
      write(*,*) "I am ", self
   end subroutine output

end module real64_module

program printx

   use real64_module

   real(real64) :: x

   x = 4.9d0
   call x%output()
   
end program printx
\end{lstlisting}


\section{Declaration of run-time polymorphic variables (trait objects)}
\label{sect:trait_objects}

Named abstract interfaces/traits are types in their own right. Their
main purpose is to allow the programmer to declare (and thereby
constrain) polymorphic variables in terms of them. Either directly,
i.e. as objects of such interfaces/traits in run-time polymorphism, as
demonstrated in this section. Or indirectly, as constraints on generic
type parameters in compile-time polymorphism (see
Sect.~\ref{sect:generic_parameters} for examples of the latter).

\subsection{Class specifier using traits}

In order to use abstract interfaces to support run-time polymorphic
objects through subtyping, Fortran's \code{class} specifier for
polymorphic variable declarations needs to be enhanced to accept named
abstract interfaces/traits, like in the declarations of the following
two variables (that make use of the \code{IAddable} interface of
Sect.~\ref{sect:interface_defs})
\begin{lstlisting}[language=LFortran,style=boxed]
  class(IAddable), allocatable :: adder
  class(IAddable), pointer     :: adderptr
\end{lstlisting}
or the following declaration of a procedure argument:
\begin{lstlisting}[language=LFortran,style=boxed]
  class(IAddable), intent(inout) :: adder
\end{lstlisting}
The semantics here are that whenever a named abstract interface
appears within the \code{class} specifier of an object's declaration,
then all the \code{public} methods of that object whose signatures are
prescribed by the adopted interface (like \code{IAddable} in the
above examples), will make use of late binding. That is, their calls
will be resolved by the run-time system of the language (e.g. through
a virtual method table).

In accordance with how objects that make use of run-time polymorphism
through subclassing (i.e. implementation inheritance) are declared in
the present Fortran standard, also ``trait objects'' (like
\code{adder}, and \code{adderptr} in the examples above) must either
be declared using the \code{allocatable}, or the \code{pointer}
attribute, or they must be arguments of a procedure. The proposed
additions are therefore backwards compatible with the functionality
that is already available in the present language. See also
Sect.~\ref{sect:type_sets} for further information on the \code{class}
specifier when used with abstract interfaces.


\subsection{Class specifier using trait combinations}

The \code{ICalculable} interface of Sect.~\ref{sect:extends_spec}
derives from the \code{IAddable} and \code{ISubtractable} interfaces
that were discussed in Sect.~\ref{sect:interface_defs}. Objects that
require the combined functionality of both these latter interfaces
could thus be declared in terms of the \code{ICalculable} interface as
follows:
\begin{lstlisting}[language=LFortran,style=boxed]
   class(ICalculable), allocatable :: addsub
\end{lstlisting}
It happens relatively often, though, that one needs to declare objects
that conform to multiple interfaces, but where one would not like to
specifically code some (otherwise unneeded) intermediary interface,
that derives from these. In such cases, it should be possible to
express an object's declaration more directly, as in the following
example
\begin{lstlisting}[language=LFortran,style=boxed]
   class(IAddable,ISubtractable), allocatable :: addsub
\end{lstlisting}
in which object \code{addsub} again conforms to both the
\code{IAddable} and \code{ISubtractable} interfaces.


\section{Derived types}

\subsection{Implements and sealed attributes}

For reasons of regularity in the language, it should be possible to
implement interfaces also directly from within derived type
definitions. This can be accomplished by allowing an \code{implements}
\emph{attribute} within such definitions. The following code shows how
the ``one fell swoop'' example of
Sect.~\ref{sect:implementing_traits}, that was written there in terms
of an \code{implements} statement, can be reformulated to use an
\code{implements} derived type attribute:
\begin{lstlisting}[language=LFortran,style=boxed]
module basic
   ...
   type, sealed, implements(IAddable,ISubtractable) :: Calculable
      private
      real :: a
   contains
      procedure, public, pass(self) :: add, sub
   end type Calculable

contains

   function add(self,other) result(res)
      type(Calculable), intent(in) :: self, other
      type(Calculable)             :: res
      res%a = self%a + other%a
   end function add

   function sub(self,other) result(res)
      type(Calculable), intent(in) :: self, other
      type(Calculable)             :: res
      res%a = self%a - other%a
   end function sub

end module basic      
\end{lstlisting}

This example also demonstrates the use of another, new, derived type
attribute, the \code{sealed} attribute. Derived types that are
\code{sealed} are inextensible by type extension, i.e. class
inheritance. Thus, there's also no need for the passed-object dummy
arguments of such types to be polymorphic, and hence for the
programmer to declare them with the \code{class} specifier. One can
use the \code{type} specifier, instead, as it is demonstrated in the
implementation of the \code{add} and \code{sub} methods of this
example.

\subsection{Interoperability with subclassing}

The multiple interface inheritance (i.e. subtyping) features, provided
by the \code{implements} statement, and \code{implements} derived type
attribute, are interoperable with the single implementation
inheritance (i.e. subclassing or type extension) which is already
present in the language. That is, code examples like the following are
possible:
\begin{lstlisting}[language=LFortran,style=boxed]
   type :: Parent
   contains  
      procedure :: method1
      procedure :: method2
   end type Parent

   type, extends(Parent), implements(IChild) :: Child
   contains  
      procedure :: method3
      procedure :: method4
   end type Child
   ...
\end{lstlisting}
Here, a \code{Child} type is defined, that inherits two methods
(\code{method1} and \code{method2}) from a \code{Parent} type, and
adds two further methods of its own (\code{method3} and
\code{method4}), in order to conform to an interface, \code{IChild},
that consists of the signatures of all four of these methods. In such
use cases, the \code{extends} attribute shall always precede the
\code{implements} attribute.

Thus, the features which are described here are backwards compatible
with the OO model that is used in the present language. Moreover,
since both the new \code{implements} statement and derived type
attribute allow for inheritance of \emph{multiple} interfaces (see
Sect.~\ref{sect:implementing_traits}), this also fixes present
Fortran's single inheritance limitations, \emph{without} introducing
the potential ambiguities that multiple inheritance of implementation
would cause (which are also known as ``The Diamond Problem'').


\chapter{Fortran extensions II: Generics}

The new subtyping features that were discussed in the previous chapter
are required in order to uniformly express and support both run-time
and compile-time polymorphism in Fortran. We will now proceed with
discussing further enhancements that are specifically needed in order
to support compile-time polymorphism, i.e. generics.

\section{Enhancements to interfaces}

\subsection{Generic procedure signatures} 
\label{sect:generic_interfaces}

Abstract interfaces should be allowed to contain signatures of generic
procedures, as in the Swift language. The approach taken in Go and
Rust, to instead parameterize the abstract interfaces themselves, is
not as attractive from a user's perspective
(cf. Sect.~\ref{sect:Swift}). The following code shows, as an example,
an abstract interface called \code{ISum} that contains the signature
intended for a generic type-bound procedure (i.e. generic method),
named \code{sum}:
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: ISum
      function sum{INumeric :: T}(self,x) result(s)
         deferred(self), intent(in) :: self
         type(T),        intent(in) :: x(:)
         type(T)                    :: s
      end function sum
   end interface ISum
\end{lstlisting}

The example illustrates the use of a generic type parameter, that is
simply called \code{T} here, in terms of which the regular function
arguments are declared. A significant difference of generic type
parameters, as compared to regular function arguments, is that the
former will be substituted by an actual type argument at compile time,
in a process called instantiation.

A similarity is that, in the same way that regular function arguments
need to be constrained by a provided type, type parameters need to be
constrained by a provided meta-type. This (meta-type) constraint must
be an abstract interface name (like \code{INumeric} in the present
example), that precedes the actual type parameter name. The proposed
Fortran generics thus support ``strong concepts'', and can be fully
type-checked by the compiler. Both, the type parameter and its
constraint, are part of a generic type parameter list that is enclosed
in curly braces, and follows immediately behind the procedure's
name. Notice that the syntax used above, that deviates slightly from
how Fortran's regular function arguments are declared, appears
justified, as it reflects that, despite some similarities, in type
parameters one is dealing with different entities.

\subsection{Type sets}
\label{sect:type_sets}

In order to make the interface based generics facility easy to use
with intrinsic types (and the multitude of intrinsic procedures that
Fortran supports for these types), it must be possible, as in the Go
language, to define generics constraints by means of abstract
interfaces that consist of type sets.

\subsubsection{Unions of types}

The following example shows the simplest form of such a type set, by
defining an interface \code{INumeric}, for use as a generics
constraint in the example of Sect.~\ref{sect:generic_interfaces}, in
order to admit for the type parameter \code{T}, that was given there,
only the (32 bits wide) default \code{integer} intrinsic data type:
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: INumeric
      integer
   end interface INumeric
\end{lstlisting}

The above example is actually a special case of specifying entire
\emph{unions} of member types as a type set. A type set consisting of
such a union of types is demonstrated in the following example
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: INumeric
      integer | real(real64)
   end interface INumeric
\end{lstlisting}
that redefines interface \code{INumeric} such as to admit either the
default 32 bit \code{integer}, or the 64 bit \code{real} type as a
generics constraint.

The semantics of such a type set construct are that it implicitly
defines a \emph{set of function signatures}, namely the signatures of
the intersecting (common) set of all the operations and intrinsic
functions (also called methods in the following) that work with all
the member types of the type set. This can also be restated, by saying
that a type \code{T} \emph{implements} an interface consisting of such
a type set, if (and only if) it is a member type of this set. For
instance, Fortran's various \code{complex} types are not members of
interface \code{INumeric}'s type set (as it is given above), because
they do not appear in its definition. Hence, none of the
\code{complex} types implements the \code{INumeric} interface. In
particular, the \code{complex} types do not support, i.e. implement,
the relational operators \code{(<)} and \code{(>)} that are required
for conformance to this interface, given that these operators are
implemented by both the \code{integer} and \code{real(real64)} member
types.

\subsubsection{Assumed kind parameters}

Expanding on the previous example, an \code{INumeric} interface that
might be even more useful as a generics constraint, for a number of
tasks, could be coded as follows:
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: INumeric
      integer(*) | real(*) | complex(*)
   end interface INumeric
\end{lstlisting}
Notice how this makes use of both unions of types, and assumed
(i.e. wildcard) kind parameters for types, to include \emph{all}
\code{integer}, \code{real}, and \code{complex} types, that are
admitted by the language, in a single \code{abstract interface}
constraint.

The use of assumed kind parameters is here merely syntactic sugar
that allows one to avoid having to write out a type set for all
the possible kinds of a type. For instance, if the particular Fortran
implementation supports \code{real(real32)} and \code{real(real64)} as
its only \code{real} types, then \code{real(kind=*)}, or
\code{real(*)} for short, is understood to mean the type set
``\code{real(real32) | real(real64)}''. Notice, also, that the more
types are added to an interface in this fashion, the smaller the set
of intersecting methods will usually become.

\subsubsection{Empty interface}

In the limit of adding all possible types to a type set, there won't
be any common methods left that are implemented by all its types. This
results in the important case of the empty interface, that matches all
types (since any type has at least zero methods):
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: IAnyType
   end interface IAnyType
\end{lstlisting}

\subsubsection{Implicit notation}

For simple use cases, it should be optionally possible for the
programmer to employ a shorter notation for declaring type constraints
for generics, than having to define an explicit interface of type
sets, like \code{INumeric} above, and to then use it as in
Sect.~\ref{sect:generic_interfaces}. The following modification of
interface \code{ISum}'s original declaration of
Sect.~\ref{sect:generic_interfaces}, provides such an example:
\begin{lstlisting}[language=LFortran,style=boxed]
   abstract interface :: ISum
      function sum{integer | real(real64) :: T}(self,x) result(s)
         deferred(self), intent(in) :: self
         type(T),        intent(in) :: x(:)
         type(T)                    :: s
      end function sum
   end interface ISum
\end{lstlisting}
The notation within the generic type parameter list in curly braces
defines a type set interface implicitly, to be used as a type
constraint for type \code{T}. In this particular case, to admit only
the 32 bit \code{integer}, or 64 bit \code{real} type for \code{T},
as discussed above.

\subsubsection{Predefined constraints}

The facilities described in this section are flexible enough for the
user to be able to construct frequently required generics constraints
himself, the way he needs them. Nevertheless, the language should
ideally also supply a collection of predefined, commonly used generics
constraints in the form of abstract interfaces that are contained in a
language-intrinsic module, tentatively called
\code{generics\_constraints} here. The list of such predefined
interfaces could include
\begin{itemize}
\item
  an empty interface of the name \code{IAnyType} (as shown above),
\item
  some predefined numeric interfaces allowing for different
  numeric operations, but also
\item
  some predefined interfaces to allow for the use of relational
  operators with different intrinsic types.
\end{itemize}

Such interfaces could then be imported from user code through a
\code{use} statement like in the following example that assumes the
existence of a language defined interface \code{INumeric}:
\begin{lstlisting}[language=LFortran,style=boxed]
module user_code

   use, intrinsic :: generics_constraints, only: INumeric

   abstract interface :: ISum
      function sum{INumeric :: T}(self,x) result(s)
         deferred(self), intent(in) :: self
         type(T),        intent(in) :: x(:)
         type(T)                    :: s
      end function sum
   end interface ISum

end module user_code
\end{lstlisting}

\subsubsection{Present restrictions and possible future extensions}
\label{sect:future_extensions}

Interfaces that are formulated in terms of type sets are presently
\emph{exclusively} intended for use as generics constraints. Hence, a
compiler must ensure that they are \emph{not} used for any other
purpose. In particular, they are not intended to be implemented by
derived (i.e. user-defined) types\footnote{One of the problems here is
that any new intrinsic function that would be added to the language
for some intrinsic type, would change the set of methods of all the
type sets of which this type is a member. This would break any
user-defined types that would implement interfaces which are based on
these type sets.}, and they cannot be used in variable declarations
that involve the \code{class} specifier (as described in
Sect.~\ref{sect:trait_objects}).

As it was demonstrated by the aforegiven examples, interfaces that are
formulated in terms of type sets typically boil down to a set of
language-intrinsic types. Since the \code{class} declaration specifier
is undefined for intrinsic types, and since -- moreover -- the
semantics of this specifier allow for late binding of methods, which
is incompatible with intrinsic types, a compiler will need to ensure
that the \code{class} declaration specifier is not used in conjunction
with interfaces that are formulated in terms of type sets. This
includes the empty interface, \code{IAnyType}.

In a future language revision, such interfaces could, however, be
admitted for use with the \code{type} declaration specifier, in order
to enable compile-time polymorphism through union (also called sum)
types \cite{Taylor_21,Pierce_91}. This would take the present design
to its logical conclusion, offer an alternative to generic type
parameters for certain use cases, and fill a present gap in the later
to be discussed Table~\ref{tab:dispatch}.


\section{Generic casts for intrinsic types}

A language like Fortran, that is intended for numeric use, where
conversions between different intrinsic types are required rather
frequently, must allow conversions between such types to be done also
in generic code, in a similarly user-friendly fashion as it is the
case in the Go language. That is, by means that are built into the
language, without having to rely exclusively on external library
functionality.

For instance, generic routines will often have to initialize the
result of reduction operations, as it is, e.g., the case in the test
problem implementation of Sect.~\ref{sect:poly_functional}. There, a
reduction variable for summation, \code{s}, needs to be initialized to
the zero constant of type \code{T}. In Go, it is easily possible to
express this initialization by transforming the (typeless) zero
constant, \code{0}, into the corresponding constant of type \code{T},
i.e. by simply writing \code{s = T(0)}.

If, for instance, \code{T} is then instantiated at compile time with
the \code{float64} type, the expression \code{T(0)} will be
transformed by the compiler into \code{float64(0)}, i.e. a call to the
correct conversion function. In Fortran's case, the compiler would
have to translate the above expression into the intrinsic function
call \code{real(0,kind=real64)}, which should actually be easy to do,
also for all other cases where such conversion is indeed
possible. Otherwise, the compiler should emit an error message, and
abort compilation at the generics instantiation step.

\section{Generic procedures, methods, and derived types}
\label{sect:generic_parameters}

As already mentioned, Fortran's basic generics design should allow
both ordinary and type-bound procedures (i.e. methods), and derived
types to be given their own generic type parameters.

\subsection{Generic procedures}
\label{sect:generic_procedures}

Using the syntax proposed in this document, an implementation of a
Fortran function for array summation that is generic over the type of
its input array argument would look as follows\footnote{Generic
subroutines can be coded completely analogously.}:
\begin{lstlisting}[language=LFortran,style=boxed]
   function sum{INumeric :: T}(x) result(s)
      type(T), intent(in) :: x(:)
      type(T)             :: s
      integer :: i
      s = T(0)
      do i = 1, size(x)
         s = s + x(i)
      end do
   end function sum
\end{lstlisting}
The following examples will assume that the \code{INumeric} generics
constraint, that is used here, is provided by an interface that admits
both the \code{integer} and \code{real(real64)} types for \code{T}
(see Sect.~\ref{sect:type_sets}).

To actually use the \code{sum} generic function, one simply needs to
pass to it (via its regular arguments list) an argument of one of
the admitted ``numeric'' types, e.g. as in the following two calls:
\begin{lstlisting}[language=LFortran,style=boxed]
  integer      :: integer_total
  real(real64) :: float_total
  
  integer_total = sum([1,2,3,4,5])
  float_total   = sum([1.d0,2.d0,3.d0,4.d0,5.d0])
\end{lstlisting}
Here, the compiler will \emph{automatically} instantiate appropriate
versions of the \code{sum} generic function by using type inference on
the regular arguments lists. That is, the programmer can
straightforwardly use his generic routine on any of the admitted
types. Although the present design \emph{doesn't} typically require
it, the programmer can accomplish generic instantiation also manually,
by the additional provision of a generic type argument in curly
braces, as in the following two calls:
\begin{lstlisting}[language=LFortran,style=boxed]
  integer_total = sum{integer}([1,2,3,4,5])
  float_total   = sum{real(real64)}([1.d0,2.d0,3.d0,4.d0,5.d0])
\end{lstlisting}

Such manual instantiation of generic procedures is only needed in
the relatively rare cases where a regular arguments list is either
unavailable or outright inappropriate, e.g. for use in procedure
pointer assignments, or in \code{associate} statements, as in the next
example:
\begin{lstlisting}[language=LFortran,style=boxed]
  real(real64) :: dtot(2)
  real(real32) :: stot(2)
  procedure(sum_real64), pointer :: dsum

  abstract interface
     function sum_real64(x) result(s)
        real(real64), intent(in) :: x(:)
        real(real64)             :: s
     end function sum_real64  
  end interface
  
  dsum => sum{real(real64)}

  dtot(1) = dsum([1.d0,2.d0,3.d0,4.d0,5.d0])
  dtot(2) = dsum([2.d0,4.d0,6.d0,8.d0])

  associate( ssum => sum{real(real32)} )
     stot(1) = ssum([1.,2.,3.,4.,5.])
     stot(2) = ssum([2.,4.,6.,8.])     
  end associate
\end{lstlisting}

\subsection{Generic methods}
\label{sect:generic_methods}

The same summation algorithm as that of
Sect.~\ref{sect:generic_procedures}, when implemented as a generic
method, \code{sum}, that is bound to a derived type named
\code{SimpleSum}, which implements the interface \code{ISum} as it was
given in Sect.~\ref{sect:generic_interfaces}, would instead look as
follows:
\begin{lstlisting}[language=LFortran,style=boxed]
module simple_library
   ...

   type, public :: SimpleSum
   end type SimpleSum

   implements ISum :: SimpleSum
      procedure :: sum
   end implements SimpleSum
   
contains
   
   function sum{INumeric :: T}(self,x) result(s)
      class(SimpleSum), intent(in) :: self
      type(T),          intent(in) :: x(:)
      type(T)                      :: s
      integer :: i
      s = T(0)
      do i = 1, size(x)
         s = s + x(i)
      end do
   end function sum

end module simple_library
\end{lstlisting}
We have used here the \code{implements} \emph{statement} for
implementing an interface by a derived type, and will continue to
consistently do so for the remainder of this chapter. The alternative
way of employing the \code{implements} derived type \emph{attribute}
for the same purpose, is demonstrated on exactly the same examples in
Chapter~\ref{chapt:fortran_examples}.

Generic methods are used completely analogously to generic
procedures. The automatic instantiation use case of
Sect.~\ref{sect:generic_procedures} would, for instance, be written
\begin{lstlisting}[language=LFortran,style=boxed]
  type(SimpleSum) :: simple

  integer_total = simple%sum([1,2,3,4,5])
  float_total   = simple%sum([1.d0,2.d0,3.d0,4.d0,5.d0])
\end{lstlisting}
whereas the corresponding manual instantiation case would take the form:
\begin{lstlisting}[language=LFortran,style=boxed]
  type(SimpleSum) :: simple
  
  integer_total = simple%sum{integer}([1,2,3,4,5])
  float_total   = simple%sum{real(real64)}([1.d0,2.d0,3.d0,4.d0,5.d0])
\end{lstlisting}

\subsection{Generic derived types}
\label{sect:generic_derived_types}

In addition to procedures and methods, generic type parameter lists
must also be allowed for derived type definitions, as in the following
example, in which the \code{ISum} interface of
Sect.~\ref{sect:generic_interfaces} is implemented by another
derived-type, named \code{PairwiseSum}:
\begin{lstlisting}[language=LFortran,style=boxed]
module pairwise_library
   ...   
   type, public :: PairwiseSum{ISum :: U}
      private
      type(U) :: other
   end type PairwiseSum

   implements ISum :: PairwiseSum{ISum :: U}
      procedure :: sum
   end implements PairwiseSum

contains

   function sum{INumeric :: T}(self,x) result(s)
      class(PairwiseSum{U}), intent(in) :: self
      type(T),               intent(in) :: x(:)
      type(T)                           :: s
      integer :: m
      if (size(x) <= 2) then
         s = self%other%sum(x)
      else
         m = size(x) / 2
         s = self%sum(x(:m)) + self%sum(x(m+1:))
      end if
   end function sum

end module pairwise_library
\end{lstlisting}

Notice, how type \code{PairwiseSum} depends on a generic type
parameter, \code{U}, that is used within type \code{PairwiseSum}
itself in order to declare a field variable of \code{type(U)}, which
is named \code{other}. As is indicated by the type constraint on
\code{U}, object \code{other} conforms to the \code{ISum} interface
itself, and therefore contains its own implementation of the
\code{sum} procedure.

The above example furthermore demonstrates, how a derived type's
generic parameters are brought into the scope of its type-bound
procedures via the latters' passed-object dummy arguments. In this
example, type \code{PairwiseSum}'s method, \code{sum}, has a
passed-object dummy argument, \code{self}, that is declared being of
\code{class(PairwiseSum\{U\})}. Hence, method \code{sum} can now
access \code{PairwiseSum}'s generic parameter \code{U}. This
allows the method to make use of two independently defined generic
type parameters, \code{T} and \code{U}, which grants it increased
flexibility. This also means that there is \emph{no} implicit
mechanism of bringing generic parameters of a derived type into the
scope of its methods. If a type-bound procedure needs to access the
generic parameters of its derived type, it must be provided with a
passed-object dummy argument.

Notice, that the declaration \code{class(PairwiseSum\{U\})} does not
imply any ambiguities or contradictions with respect to compile-time
vs. run-time polymorphism, because substitution semantics apply. At
compile time, the compiler will substitute a set of different type
arguments for the generic parameter \code{U}. Hence, the notation
\code{PairwiseSum\{U\}} really refers to a set of multiple, related,
but \emph{different} \code{PairwiseSum} types, whose \emph{only}
commonality is that they all implement the \code{ISum} interface (and
furthermore contain different field components that do the same). Of
course, passed-object dummy arguments of any of the different
\code{PairwiseSum} types of this set can then be run-time polymorphic,
in exactly the same manner that passed-object dummy arguments of other
derived types that implement the same interface can be run-time
polymorphic.

The following code snippet finally shows how an object of the
\code{PaiwiseSum} type could be declared and instantiated statically
(by substituting its generic type parameter \code{U} by the
\code{SimpleSum} type of Sect.~\ref{sect:generic_methods}), and how
its generic \code{sum} method would be employed using automatic type
inference:
\begin{lstlisting}[language=LFortran,style=boxed]
  type(PairwiseSum{SimpleSum}) :: pairwise

  integer_total = pairwise%sum([1,2,3,4,5])
  float_total   = pairwise%sum([1.d0,2.d0,3.d0,4.d0,5.d0])
\end{lstlisting}

\section{Updated structure constructors}
\label{sect:param_constructors}

If a derived type is parameterized over a generic type, as in the
example of Sect.~\ref{sect:generic_derived_types}, then its structure
constructor must also be assumed to be parameterized over the same
generic type. Hence, calls of structure constructors, with specific
argument types substituting the generic type parameters of their
derived types, must be valid. The following (in this particular case
redundant, as demonstrated above) run-time instantiation of object
\code{pairwise} by the structure constructor of type
\code{PairwiseSum} provides such an example:
\begin{lstlisting}[language=LFortran,style=boxed]
  type(PairwiseSum{SimpleSum}) :: pairwise

  pairwise = PairwiseSum{SimpleSum}()

  integer_total = pairwise%sum([1,2,3,4,5])
  float_total   = pairwise%sum([1.d0,2.d0,3.d0,4.d0,5.d0])
\end{lstlisting}
As in Sect.~\ref{sect:generic_methods}, \code{SimpleSum} is a
derived type that implements the \code{ISum} interface, but (in
contrast to the \code{PairwiseSum} type, as implemented in
Sect.~\ref{sect:generic_derived_types}) is not parameterized by any
generic type parameter itself.

We also propose to make a further, small, but extremely important
addition to structure constructors: namely to introduce the notion
that a structure constructor is implicitly defined \emph{within the
same scope that hosts the definition of its derived type}. This would
make it possible for the structure constructor to access even
\code{private} components of its derived type, through host
association. Meaning that if the derived type is hosted within the
specification part of a module, such components would be accessible,
and thus could be initialized, even by calls to the structure
constructor that are being performed from outside this module's
scope. Which would be in complete analogy to how user-defined
constructors work in Fortran.

In this way, it would become possible to initialize \code{private},
\code{allocatable} derived type components by structure constructors,
which is absolutely crucial for concise OO programming. Since such an
extension would merely add to the capabilities of the language, it
would be fully backwards compatible. The elegance of the afore-given
Go and Swift code versions, but also of the Fortran code examples that
are presented in the next chapter is largely due to the use of such
constructors. Lacking these, user-defined constructors would have to
be employed, leading to overly complex implementations, as e.g. in the
Rust example code given in Listing~\ref{lst:OORust}.


\section{Extensibility to rank genericity}

Fortran's special role, as a language that caters to numerical
programming, demands that any generics design for the language must
allow for the possibility to also handle genericity of array rank. The
present design offers a lot of room in this respect, but since this is
a largely orthogonal issue, and since we consider a discussion of such
functionality to be non-essential for the purpose of a very first
prototype implementation of the generics features described here, we
defer it to a separate document.


\chapter{Fortran examples}
\label{chapt:fortran_examples}

In order to comprehensively illustrate how the new features, that were
discussed in the last two chapters, would be used in practice, we will
give in the present chapter several worked out examples. The first two
subsections contain both complete functional and OO Fortran code
versions of the standard test problem that is used throughout this
document. While the last two subsections deal with how to formulate
general generics constraints, and how to use associated types with
generics.

\section{Functional versions of the standard test problem}

Fortran presently lacks support for advanced functional programming
capabilities, like closures and variables of higher-order functions,
that are, e.g., available in Go and other modern languages. In
contrast to the Go version of the standard test problem that is given
in Sect.~\ref{sect:poly_functional}, the functional Fortran code
versions that are presented in this section therefore make no attempt
to eliminate rigid dependencies on user-defined function
implementations, and content themselves with demonstrating how the new
generics features can be used to eliminate rigid dependencies on
language-intrinsic types.

\subsection{Automatic instantiation of generic procedures}

Listing~\ref{lst:Func1Fortran} shows a straightforward generic
functional implementation of the test problem, that uses automatic
type inference by the compiler. The following additional remarks
should help to better understand this code:
\begin{itemize}
\item
  To express type genericity for the arguments and return values of our
  different generic functions, we make use of a type constraint
  expressed by the interface \code{INumeric}, that is implemented as the
  type set \code{integer | real(real64)}.
\item
  Interface \code{INumeric} is defined by the user himself. Thus,
  there is no need for an external dependency.
\item
  Any required conversions to generic types are done using explicit
  casts, as in Go.
\item
  \emph{All} the required instantiations of generic procedures are
  done automatically by the compiler, based on type inference of the
  regular arguments that are passed to these procedures.
\end{itemize}

\lstinputlisting[language=LFortran,style=boxed,label={lst:Func1Fortran},caption={Fortran version of the array averaging problem with
automatic generics instantiation.}]{Code/Fortran/functional1.f90}

The example demonstrates that using the new generics features together
with a functional (or procedural) programming style is easy, that the
syntax is economical, and that type inference by the compiler should
be straightforward and therefore reliable. Hence, we believe that the
generics features described here will place no burden on the
programmer.


\subsection{Manual instantiation of generic procedures}

It is actually possible to make the Fortran code version that was
given in Listing~\ref{lst:Func1Fortran}, resemble the Go code version
of Listing~\ref{lst:polyfuncGo} a bit closer, by having two procedure
pointers stand in, within the \code{select case} statement of the main
program, for the closures that were used in the Go code. As this is a
good example for demonstrating how generics can be instantiated
manually by the programmer, we give in Listing~\ref{lst:Func2Fortran}
an alternative form of the main program of
Listing~\ref{lst:Func1Fortran} that makes use of both procedure
pointers and such manual instantiation (as it was discussed in
Sect.~\ref{sect:generic_procedures}).

\lstinputlisting[linerange={53-101},language=LFortran,style=boxed,label={lst:Func2Fortran},caption={Main program using procedure pointers and manual generics instantiation.}]{Code/Fortran/functional2.f90}


\section{Object-oriented versions of the standard test problem}

The present section will demonstrate that being able to use the new
generics features seamlessly and easily even within a modern-day OO
programming setting is one of the great strengths of the present
design.

\subsection{Dynamic method dispatch}
\label{sect:Fortran_dynamic_dispatch}

Listing~\ref{lst:OOFortran} shows our encapsulated (OO) Fortran code
version of the standard test problem, that corresponds closest to the
code versions that were presented in Chapter~\ref{chapt:survey} for
all the other languages.

\begin{itemize}
\item
  As in all these other versions, three interfaces are used to manage
  all the source code dependencies in the problem: \code{INumeric},
  \code{ISum}, and \code{IAverager}. Interface \code{INumeric} is
  defined by the user himself as a type set, similar to the
  corresponding Go code.
\item
  In contrast to the Go and Rust versions (Listings~\ref{lst:OOGo}
  and \ref{lst:OORust}), none of the aforementioned interfaces is
  parameterized itself, since we followed Swift's basic model of
  generics.
\item
  Interface inheritance is expressed through the presence of the
  \code{implements} attribute in derived-type definitions (equivalent
  to the Swift version, Listing~\ref{lst:OOSwift}). Alternatively,
  \code{implements} statements could be used
  (cf. Sects.~\ref{sect:implements_stmt}, \ref{sect:generic_methods},
  and \ref{sect:generic_derived_types}).
\item
  All our derived types are \code{sealed}, which makes them
  inextensible to implementation inheritance, and thus enables us to
  declare the passed-object dummy arguments of their type-bound
  procedures with the \code{type} specifier.
\item
  The example code makes use, in the main program, of the new
  structure constructors, with their enhancements that were discussed
  in Sect.~\ref{sect:param_constructors}, for the classes
  \code{Averager}, \code{SimpleSum}, and \code{PairwiseSum}.
\item
  This Fortran version makes use of modules and \code{use} statements
  with \code{only} clauses, in order to make explicit the source code
  dependencies of the different defined classes/ADTs.
\end{itemize}

\lstinputlisting[language=LFortran,style=boxed,label={lst:OOFortran},caption={Proposed encapsulated Fortran version of the array averaging example.}]{Code/Fortran/mixed.f90}

The most important point to note, in Listing~\ref{lst:OOFortran}, is
how this code makes use of trait objects
(cf. Sect.~\ref{sect:trait_objects}) and generics to avoid rigid
dependencies on user-defined implementation and language-intrinsic
types, respectively, and to thus realize a plugin architecture that
allows for a maximum of code reuse. Notice, in particular, how the
main program is the only part of the code that (necessarily) depends
on implementations. The \emph{entire} rest of the code is decoupled,
i.e. it depends merely on abstract interfaces (see the \code{use}
statements in the above modules).

Notice also, that all the abstract interfaces that are required for
this purpose are defined by the user himself, without any need to
depend on external libraries. The OO Fortran version that is presented
here is therefore as clean as the Go implementation of
Listing~\ref{lst:OOGo} with respect to dependency management, and as
easy to use, and to read and understand, as the Swift implementation
of Listing~\ref{lst:OOSwift}.

\subsection{Static method dispatch}
\label{sect:Fortran_static_dispatch}

One of the greatest benefits of the present design is that, through
the use of generics, polymorphic methods in OO programming can be made
to use static dispatch\footnote{This can be achieved in a compiler by
implementing generic polymorphism through the (compile-time) technique
of monomorphization, that relies on static method dispatch. In
contrast to traditional (run-time) polymorphism, that relies on
virtual method tables and dynamic method dispatch.}. This will enable
inlining of polymorphic methods by the compiler, to potentially
improve code performance. Listing~\ref{lst:staticFortran} gives a
\emph{minimally} changed version of the OO Fortran code of
Listing~\ref{lst:OOFortran}, to effect static dispatch of the
different \code{sum} methods.

The required changes are confined to a parameterization of the
\code{PairwiseSum} and \code{Averager} derived types, by generic type
parameters that conform to the \code{ISum} interface and are named
\code{U}. These type parameters are then used in order to declare the
field objects \code{other} and \code{drv} of the \code{PairwiseSum}
and \code{Averager} types, respectively, by means of the \code{type}
specifier. Taken together, these changes signify compile-time
polymorphism for the objects \code{other} and \code{drv} to the
compiler, and hence static dispatch of their methods (whose interfaces
were declared in the \code{ISum} interface). Contrast this with the
\code{class} specifier, that was used previously for the declaration
of these former trait objects, in order to effect run-time
polymorphism and dynamic dispatch of their methods. See also
Table~\ref{tab:dispatch} for a summary of rules regarding method
dispatch.

Everything else, especially the declaration of these object variables
as \code{alloctable}s and their instantiation at run-time using
chaining of constructor calls, was kept the same in order to demonstrate that
static method dispatch does \emph{not} mean that the actual object
instances that contain the methods must be initialized and their
memory allocated at compile-time (although in this particular case
this is possible, as demonstrated in the next section, given that
these objects do not contain any other \code{allocatable} data fields,
like arrays). Notice, also, that none of the source code dependencies
in the \code{use} statements have changed. That is, the code is
\emph{still} fully decoupled, despite making now use of static
dispatch!

\lstinputlisting[language=LFortran,style=boxed,label={lst:staticFortran},caption={Demonstrates static method dispatch for the \code{sum} methods.}]{Code/Fortran/static1.f90}

\begin{table}[h]
\centering
\begin{tabular} {L{0.308\textwidth} C{0.308\textwidth} C{0.308\textwidth}}
  \toprule
  \textbf{object declaration} & \textbf{dynamic dispatch} & \textbf{static dispatch} \\
  \midrule
  \code{class(Interface)}   &  always             & never \\
  \code{class(DerivedType)} &  if \code{DerivedType} is \code{extend}ed &
  if \code{DerivedType} is un\code{extend}ed\tablefootnote{Or the method is declared as \code{non\_overridable}.} \\
  \code{type(DerivedType)}  &  never              & always \\
  \code{type(Interface)}  &  ---  & --- \\
  \bottomrule
\end{tabular}
\caption{Correspondence between object declarations and method
  dispatch strategies that would be typically employed by an
  optimizing Fortran compiler according to the present document. A
  dash indicates that the case in question is presently undefined, but
  could be used for a future extension as discussed in
  Sect.~\ref{sect:future_extensions}.}
\label{tab:dispatch}
\end{table}

The \code{av} object of \code{IAverager} type, in
Listing~\ref{lst:staticFortran}, still needs to make use of run-time
polymorphism, because it is initialized in a \code{select case}
statement by the main program. This object cannot be made to employ
compile-time polymorphism, as it is initialized within a statement
that performs a run-time decision.

As in corresponding Swift and Rust implementations of the standard test
problem, that are not fully reproduced here (see the accompanying code
directory), the instantiation (in the main program) of the objects
\code{other} and \code{drv} through constructor calls, has the benefit
that the compiler can infer the correct type arguments, that are
required to automatically instantiate all the involved generic derived
types. Hence (and similarly to both the functional and OO code
versions of Listings~\ref{lst:Func1Fortran} and ~\ref{lst:OOFortran},
respectively), not a single manual instantiation of generics is
necessary, anywhere, in Listing~\ref{lst:staticFortran}.

As a final remark, we'd like to emphasize that, on readability grounds,
a coding style as that given in Listing~\ref{lst:OOFortran} is
generally preferable over that of
Listing~\ref{lst:staticFortran}. The use of numerous generic type
parameters can quickly make code unreadable. We'd therefore recommend
the default use of run-time polymorphism for managing dependencies on
user-defined types, and the employment of generics for this latter
task merely in cases where profiling has shown that static dispatch
would significantly speed up a program's execution (by allowing method
inlining by the compiler). Of course, the use of generics to manage
dependencies on language-intrinsic types remains unaffected by this
recommendation.

\subsection{Static method dispatch and static object declarations}

In the present simple example, and taking Listing~\ref{lst:staticFortran}
as a baseline, it is actually possible to even avoid some of the
run-time memory allocation overhead of the program, by having the
field objects \code{other} and \code{drv}, that are contained within
the \code{PairwiseSum} and \code{Averager} types, be statically
declared. To accomplish this, the two lines
\begin{lstlisting}[language=LFortran,style=boxed]
  type(U), allocatable :: other
  type(U), allocatable :: drv
\end{lstlisting}
in Listing~\ref{lst:staticFortran} need to be replaced by the
following two code lines:
\begin{lstlisting}[language=LFortran,style=boxed]
  type(U) :: other
  type(U) :: drv
\end{lstlisting}

Notice, that even in this code version, and because the compiler
should be able to automatically infer generic type arguments from the
types of regular arguments in constructor calls, the object
instantiations that are to be carried out from the main program can
remain the same, that is:
\begin{lstlisting}[language=LFortran,style=boxed]
  avs = Averager(drv = SimpleSum())
  avp = Averager(drv = PairwiseSum(other = SimpleSum()))
\end{lstlisting}
Thus making manual instantiation of generic types unnecessary.

Alternatively, though, the two calls of \code{Averager}'s structure
constructor could be manually given generic type arguments to confirm
the types of the regular arguments (deleting here the latters'
keywords):
\begin{lstlisting}[language=LFortran,style=boxed]
  avs = Averager{SimpleSum}(SimpleSum())
  avp = Averager{PaiwiseSum{SimpleSum}}(PairwiseSum(SimpleSum()))
\end{lstlisting}

Or one could delete the regular arguments to the constructor
altogether, and provide only the generic type arguments, as follows
(see Sect.~\ref{sect:param_constructors}):
\begin{lstlisting}[language=LFortran,style=boxed]
  avs = Averager{SimpleSum}()
  avp = Averager{PairwiseSum{SimpleSum}}()
\end{lstlisting}
The full source code for this version of the test problem can be found
in the \code{Code} subdirectory that is accompanying this document.


\section{Employing general generics constraints}
\label{sect:types}

In the previous examples of this chapter, we made predominant use of
generics constraints that, like the interface \code{INumeric}, were
formulated as type set unions of intrinsic types. While this is a very
frequently occuring use case, it is of course possible to formulate
generics constraints in a more general manner, through explicit
specification of procedure signatures in abstract interfaces. One
example was already given in the form of the \code{ISum} interface,
that was used as a generics constraint for derived types in
Listing~\ref{lst:staticFortran}.

Another example is shown in the following
Listing~\ref{lst:types}. This listing provides a main program with an
internal \code{generic\_sum} function, whose generic type parameter,
\code{T}, is constrained by the interface \code{IAdmissible} of
Sect.~\ref{sect:generic_stmt}. This interface requires not only
numeric functionality in the form of a custom addition operator, but
also custom type-conversion functionality. Listing~\ref{lst:types}
provides also two modules that implement both this \code{IAdmissible}
interface, and the \code{IPrintable} interface of
Sect.~\ref{sect:interface_defs}, for two different data types.  A
derived type with name \code{MyType} illustrates the procedure of
implementing these interfaces for a user-defined type, while the same
is also shown for the \code{real} type, as an intrinsic type example.
This serves to enable the use of \emph{both} these types with the
\code{generic\_sum} function, but also with a second internal
subroutine, called \code{printout}, that requires I/O functionality.

\lstinputlisting[language=LFortran,style=boxed,label={lst:types},caption={Example of using non-type-set interfaces as generics constraints for procedures.}]{Code/Fortran/types.f90}


\section{Associated type usage with generics}

Lastly, we will demonstrate, now, how associated types in abstract
interfaces (as they were introduced in Sect.~\ref{sect:assoc_types}),
can be used in conjunction with implementing types that are
parameterized over some generic parameter. The following example
defines an abstract interface, \code{IAppendable}, that requires any
implementing type to provide functionality for appending some item to
itself. This interface contains two associated types: an alias,
\code{deferred(self)}, for the type of the passed-object dummy
argument of an implementing derived type, and a placeholder,
\code{deferred(item)}, for the type of the appendable items, that
needs to be supplied by an actual implementation of that interface.

\lstinputlisting[language=LFortran,style=boxed]{Code/Fortran/vector.f90}

An example of such an implementation of interface \code{IAppendable}
is provided here by the derived type \code{Vector}, that stores an
\code{elements} array of generic type \code{U}, where the type
parameter \code{U} conforms to the \code{IAnyType} constraint. Notice,
that in order to maintain consistency between the type of the
\code{elements} array, and any new \code{item} that we wish to append
to it, we must force the \code{item} argument of method \code{append}
to be of type \code{U} as well, as it is shown in this method's actual
implementation. In order to accomplish this enforcement without
contradicting interface \code{IAppendable}'s definition (that doesn't
know anything about type \code{U}), we made use of the placeholder
(i.e. associated) type \code{deferred(item)} in the latter
interface. Given method \code{append}'s implementation, the compiler
will then infer \code{deferred(item)} to be of the actual
\code{type(U)}.

Associated types thus allow one to make interfaces generic, without
having to parameterize either them or their method signatures by
actual generic type parameters, and to thereby entail the
instantiation needs of the latter, and the potential duplication of
client code that this can result in
(cf. Sect.~\ref{sect:Go_encapsulated}). Associated types are therefore
an important element of the present generics design, and its
philosophy not to burden the user with superfluous manual
instantiations of generics.


\chapter{Conclusions}

The Fortran extensions, that are described in this document for both
run-time and compile-time polymorphism, resulted from the consistent
application of orthogonal language design. That is, significant new
capabilities are provided through the simple extension of already
existing Fortran features, and their mutual interaction, rather than
the addition of (inappropriate and superfluous) new
constructs. Indeed, only in one single case (the \code{implements}
statement of Sect.~\ref{sect:implements_stmt}) did we find it
necessary to introduce a new language feature. But even then, it was
ensured that the new feature would be of \emph{equal} utility in
supporting both compile-time and run-time polymorphism, so that
orthogonality, again, prevailed.

The end result is a language that is both much easier to use, and much
more powerful, than that of competing approaches which prefer to
abandon the proven philosophy of orthogonal design. The presented
extensions are fully backwards compatible with the present Fortran
language, and (in stark contrast to competing approaches) allow for a
consistent use of fully type-checked generics not just in procedural
and functional, but \emph{also} in OO programming settings,
\emph{including} the support of static method dispatch (which can
improve the performance of polymorphic methods by facilitating
inlining via the compiler).

Taken together, these capabilities will allow for the uniform
management of source code dependencies on both language-intrinsic and
user-defined types in Fortran. They will enable the Fortran programmer
to write unprecedented modular code, that is on par with the most
modern languages in terms of reusability, and moreover does not
sacrifice any computational performance. The present design achieves
all of this largely \emph{without} requiring manual instantiations of
generics, and it furthermore provides a solid foundation for a number
of possible future extensions, like support for array-rank genericity,
and compile time polymorphism via union (sum) types.

\printbibliography

\renewcommand{\abstractname}{Acknowledgements}

\begin{abstract}
We thank Robert Griesemer of the Go language team for providing the
original code version from which Listing~\ref{lst:polyfuncGo} was
derived, and for his and the Go team's inspirational work on type sets
in Go generics, on which a good fraction of the present design for
Fortran is based. In the same vein, we also thank the many developers
of the Swift, Rust, and Carbon languages who, through their work, have
also influenced the present design.
\end{abstract}

\end{document}
